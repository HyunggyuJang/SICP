#+TITLE: Projects from SICP 2005
* Project 1 -- Those amazing Red Sox!
** Purpose
The purpose of Proejct 1 is for you to gain experience with writing and testing
relatively simple procedures. For each problem below, include your code as well
as comments and explanations of your code, *and* demonstrate your code's
functionality against a set of test cases. You should always create and include
your own additional, meaningful test cases in addition to provided test code to
ensure that your code works not only on typical inputs, but also on "boundary"
or difficult cases. Get in the habit of writing and running these test cases
after *every* procedure you write -- no matter how trivial the procedure may
seem to you.
** Scenario
As you may have noticed this past fall (note that the time of being texted was
2005), a remarkable event took place -- the Boston Red Sox won the World Series
for the first time in 86 years! You may also have noticed long time Boston
residents (such as MIT professors) walking about in a state of bliss. Because
many of these folks don't want to have to wait another 86 years for this to
happen again (which happened last year, I mean 2018), "Red Sox Nation" has hired
us to provide some help. In particular, we are to investigate the possibility of
perfecting a baseball robot ("basebot") that can accurately throw and can hit
with power.
** Problem 1: Some simple physics
We are going to begin by modeling how far a baseball can travel -- the same
physics will hold for both hitting a ball and throwing a ball. We are going to
simplify things by assuming that baseballs don't spin as they move (clearly
false but it makes life much easier). This means we can treat the movement of a
baseball as if it were restricted to a two-dimensional plane. So what happens
when a baseball is hit? For the moment, we'll model a baseball as a particle
that moves along a single dimension with some initial position /u/, some initial
velocity /v/, and some initial acceleration /a/. The equation for the position
of the baseball at time /t/, given /a/, /v/, and /u/ is
$u_{t}= 1/2 a t^{2} + v t + u$. Note that this denotes a first order
differential equation in time. Later, we can apply this equation to either the
horizontal ($x$) component of baseball motion, or the vertical ($y$) component
of baseball motion.

Write a procedure that takes as input values for =a, v, u,= and =t= and returns
as output the position of the baseball at time =t=:
#+BEGIN_SRC scheme
(define position
  (lambda (a v u t)
    (+ (* (/ a 2)
	  (square t))
       (* v t)
       u)))
#+END_SRC

Then test:
#+BEGIN_SRC scheme
1 (user) => (position 0 0 0 0)

;Value: 0

1 (user) => (position 0 0 20 0)

;Value: 20

1 (user) => (position 0 5 10 10)

;Value: 60

1 (user) => (position 2 2 2 2)

;Value: 10

1 (user) => (position 5 5 5 5)

;Value: 185/2
#+END_SRC

As our code of =position= just return the computed value, not through branch, so
we tested all the branches of the procedure.
** Problem 2: Basic Math
One of our goals is to determine how far a baseball will travel in the air, if
it is hit with some initial velocity at some initial angle with respect to the
ground. To do this, we will need to know when the baseball hits the ground, and
for that we'll want to find when the $y$ coordinate of the baseball's position
reaches zero. This can be discovered by finding the roots of the $y$ position
equation, and selecting the one that is larger (later in time). The proper tool
for this is the quadratic formula. Given the coefficients of the quadratic
equation $a z^{2} + b z + c = 0$, write a procedure to find one of the roots
(call this =root1=), and another procedure to find the other root (call this
=root2=).

#+BEGIN_SRC scheme
(define root1
  (lambda (a b c)
    (let ((D (- (square b)              ;b^2 - 4ac
		(* 4 a c))))
      (if (< D 0)
	  false				;invalid input
	  (/ (- (- b) (sqrt D))
	     (* 2 a))))))

(define root2
  (lambda (a b c)
    (let ((D (- (square b)              ;b^2 - 4ac
		(* 4 a c))))
      (if (< D 0)
	  false				;invalid input
	  (/ (+ (- b) (sqrt D))
	     (* 2 a))))))
#+END_SRC

And also test:
#+BEGIN_SRC scheme
(root1 5 3 6)				;when D < 0
;Value: #f
(root1 1 2 1)				;when D = 0
;Value: -1
(root1 1 4 2)				;when D > 0
;Value: -3.414213562373095
(root2 5 3 6)				;when D < 0
;Value: #f
(root2 1 2 1)				;when D = 0
;Value: -1
(root2 1 4 2)				;when D > 0
;Value: -.5857864376269049
#+END_SRC
This code constitute path-complete test.
** Problem 3: Flight Time
Given an initial upward velocity (in meters per second, or m/s) and initial
elevation or height (in meters, or m), write a procedure that computes how long
the baseball will be in flight. Remember that gravity is a downward acceleration
of 9.8m/s^{2}. Note that to solve this you will need a root of a quadratic
equation. Try using =root1=, and using =root2=. Only one of these solutions
makes sense. Which one? And why? Use this to create a correct version of the
procedure below.

Note that
\begin{align*}
\left.
\begin{matrix}
a &<0\\
b &>0\\
c &>0\\
\end{matrix}
\right\}
\implies
\frac{-b - \sqrt{D}}{2a} > 0 > \frac{-b + \sqrt{D}}{2a}
\end{align*}
as noted above our acceleration is negative initial, velocity would be positive
as it given upward velocity, and as the initial height should be positive, our
situation fit into above equation, which indicate =root1= would suit in our
case:
#+BEGIN_SRC scheme
(define time-to-impact
  (lambda (vertical-velocity elevation)
    (if (and (negative? elevation)
             (negative? vertical-velocity)) ;cannot hit the grount at any time > 0
        false
        (root1 (- (/ gravity 2)) vertical-velocity elevation)))) ;with other possibitities coped by root1 procedure.
#+END_SRC

Also note that in any case, as long as the acceleration is negative, following
equation holds when $D > 0$
\[
\frac{-b - \sqrt{D}}{2a} > \frac{-b + \sqrt{D}}{2a}
\].

So, we used this fact in above procedure.

As usual, here is the test:
#+BEGIN_SRC scheme
(time-to-impact 10 3)			;positive initial velocity with positive elevation
;Value: 2.306284408328438
(time-to-impact -20 3)			;negative initial velocity with positive elevation
;Value: .14485889559025134
(time-to-impact 1 -2)			;positive initial velocity with negative elevation, whose condition cannot hit the ground. Note that it handled by root1 procedure.
;Value: #f
(time-to-impact -2 -3)			;negative initial velocity with negative elevation; cannot hit the ground.
;Value: #f
#+END_SRC

In some cases, we may want to know how long it takes for the ball to drop to a
particular height, other than 0. Using your previous procedures as a template,
write a procedure that computes the time for the ball to reach a given target
elevation.

As we already path-completed the previous procedure, we are good to use that
procedure to this:
#+BEGIN_SRC scheme
(define time-to-height
  (lambda (vertical-velocity elevation target-elevation)
    (time-to-impact vertical-velocity (- elevation target-elevation))))
#+END_SRC
** Problem 4: Flight Distance
Suppose the baseball is hit with some velocity $v$, at a starting angle \alpha
relative to the horizontal (in degrees), and from an initial elevation (in
meters). We wish to compute the distance in the horizontal direction the
baseball will travel by the time it lands.

Write a procedure =travel-distance-simple= that returns the lateral distance the
baseball thrown with given velocity, angle, and initial elevation will travel
before hitting the ground.

We are going to encode following mathematical equation directly:
\begin{align*}
v_{x} &= v \cos \alpha\\
d_{x} &= v \cos \alpha \times t_{\text{impact}}
\end{align*}
#+BEGIN_SRC scheme
(define travel-distance-simple
  (lambda (elevation velocity angle)
    (let ((alpha (degree2radian angle)))
      (let ((v_x (* velocity
                    (cos alpha)))
            (v_y (* velocity
                    (sin alpha))))
        (* v_x
           (time-to-impact v_y elevation))))))
#+END_SRC

Here is the test cases:
#+BEGIN_SRC scheme
(define case1 (travel-distance-simple 1 45 0)) ;case 1
case1                                          ;meter
;Value: 20.32892781536815
(meters-to-feet case1)                         ;feet
;Value: 67.0854617907149
(define case2 (travel-distance-simple 1 45 45)) ;case2
case2                                           ;meter
;Value: 207.6278611514906
(meters-to-feet case2)                          ;feet
;Value: 685.171941799919
(define case3 (travel-distance-simple 1 45 90)) ;case 3
case3                                           ;meter
;Value: 5.496418989612468e-4
(meters-to-feet case3)                          ;feet
;Value: 1.8138182665721145e-3
#+END_SRC

Notice the distance traveled in feet for a ball hit at a 45 degree angle, with
this bat speed. Seems incredible -- right? We'll come back to this in a little bit.

Wow.. 207 meters...
** Problem 5: What's the best angle to hit?
Before we figure out why professional players don't normally hit 700 foot home
runs, let's first see if we can find out the optimal angle at which to launch a
baseball, in order to have it travel the furthest.

To find the best angle to hit, we design iterative process as follows:
1. Set initial max distance with max angle (0 and 0 would suffice).
2. If angle greater than upper bound then return max angle.
3. Calculate distance with the current angle.
4. If that distance greater than max distance, set max distance to current
   distance and max angle to current angle.
5. Increment angle with the given step.
6. Iterate 2 \to 5.


Here is the straightforward encode:
#+BEGIN_SRC scheme
(define (find-best-angle velocity elevation)
  (define upper-bound 90)
  (define increment 1)
  (define (next ang) (+ ang increment))
  (define (iter angle max-dist max-ang)
    (if (> angle upper-bound)
        max-ang
        (let ((dist (travel-distance-simple elevation velocity angle)))
          (let ((next-ang (next angle)))
            (if (> dist max-dist)
                (iter next-ang dist angle)
                (iter next-ang max-dist max-ang))))))
  (iter 0 0 0))
#+END_SRC

And here is the test or sample points:
#+BEGIN_SRC scheme
1 (user) => (find-best-angle 45 1)

;Value: 45

1 (user) => (find-best-angle 23 0.8)

;Value: 45

1 (user) => (find-best-angle 21 10)

;Value: 40
;; ↑ is not practical to our situation where we consider the baseball hitten by batter.
#+END_SRC
So we can conclude that in the baseball hitting case, 45 degrees is best angle
to hit the ball.
** Problem 6: So why aren't baseball outfield 600 feet deep?
Let's go back to our distances. Why are these numbers for distances hit so
unrealistic? -- because we haven't accounted for air fiction or drag. (Of course
there are some other effects, like spin, but we'll just stick with drag). Let's
think about this. Newton's equation basically says that the movement of the ball
will be governed by:
#+BEGIN_CENTER
Drag + gravity = mass * acceleration
#+END_CENTER

We can get the mass of a baseball (.15kg). We know that force due to gravity --
mass * 9.8 m/s^{2}. The force due to drag is given by:
#+BEGIN_CENTER
$1/2 C \rho A V^{2}$
#+END_CENTER
Where $C$ is the drag coefficient (about 0.5 for baseball sized objects); \rho
is the density of air (about 1.25 kg/m^{3} at sea level for moderate humidity --
not a bad approximation for Boston, but about 1.06 for Denver); $A$ is the
cross-sectional area of the baseball (which is $\pi D^{2}/4$, where $D$ is the
diameter of a baseball -- about 0.074 m). Let's denote $1/2 C \rho A$ by the
constant $\beta$. Then we see that the drag on a baseball is basically
proportional to the square of the velocity of the ball. So there is more drag
when the ball is moving faster.

How can we compute the distance traveled by a baseball, but taking into account
this drag effect? Basically we have four coupled linear differential equations:
Let's let $x$ and $y$ denote the two components of position of the baseball, and
let's let $u$ denote the velocity in the horizontal direction, and $v$ denote
the velocity in the vertical direction. We will let *V* denote the magnitude of
the velocity. Then the equations of motion are:
\begin{align*}
dx/dt &= u\\
dy/dt &= v\\
du/dt &= - \frac{1}{m} \sqrt{u^{2} + v^{2}} u \beta \\
dv/dt &= - \frac{1}{m} \sqrt{u^{2} + v^{2}} v \beta - g
\end{align*}

We can rewrite these as
\begin{align*}
dx &= u dt\\
dy &= v dt\\
du &= - \frac{1}{m} \sqrt{u^{2} + v^{2}} u \beta dt\\
dv &= - \left\{ \frac{1}{m} \sqrt{u^{2} + v^{2}} v \beta + g \right\} dt
\end{align*}

We also have some initial conditions on these parameters

\begin{align*}
x_{0} &= 0\\
y_{0} &= h\\
u_{0} &= \text{\bf{V}} \cos \alpha \\
v_{0} &= \text{\bf{V}} \sin \alpha
\end{align*}
where \alpha is the angle of the initial hit with respect to the ground, $V$ is
the initial velocity, and $h$ is the initial height of the ball.

To find the distance traveled, we need to integrate these equation (one can
consider this as second ordered differential equation with respect to $x,y$, but
this equation is not linear; thus we rely on the numerical integration anyway).
That is, starting with the initial values, we want to move forward a small step
in time (say 0.01 seconds), and compute the change in $x$ and $y$. Similarly, we
want to compute the change in $u$ and $v$, and thus, the new values for $u$ and
$v$. We can keep recursively estimating these values until the value for $y$
drops below 0, in which case the value for $x$ tells us the distance traveled.

This constitute algorithm that compute the distance traveled informally; that
is, it dictated termination condition, initial condition, and way to transit one
step. Let's restate what described above as algorithm:
1. Start with initial condition.
2. If termination condition? return $x$
3. Transition one step.
4. Iterate 2 \to 3.


Here as we explained all the details above informal description, omitted that
informations to avoid to get bogged down by that.

And here is the code:
#+BEGIN_SRC scheme
(define integrate                       ;returns x when y becomes negative.
  (lambda (x0 y0 u0 v0 dt g m beta)
    (define (iter x y u v)
      (if (< y 0)                       ;termination condition
          x
          (let ((speed (sqrt (+ (square u)
                                (square v))))
                (v-factor (* (/ 1 m)
                             beta)))
            (let ((dx (* u dt))
                  (dy (* v dt))
                  (du (* (- v-factor)
                         speed
                         u
                         dt))
                  (dv (* (- (+ (* v-factor
                                  speed
                                  v)
                               g))
                         dt)))
              (iter (+ x dx)            ;transition
                    (+ y dy)
                    (+ u du)
                    (+ v dv))))))
    (iter x0 y0 u0 v0)))                ;initial condition
#+END_SRC

And the initial setter:
#+BEGIN_SRC scheme
(define (travel-distance elevation speed angle)
  (let ((alpha (degree2radian angle)))
    (integrate 0
               elevation
               (* speed
                  (cos alpha))
               (* speed
                  (sin alpha))
               0.01
               gravity
               mass
               beta)))
#+END_SRC

And as we told, we determine the distance a baseball will travel with an angle
of 45 degrees, using velocities of 45 m/s, 40 m/s, 35 m/s:
#+BEGIN_SRC scheme
1 (user) => (meters-to-feet (travel-distance 1 45 45))

;Value: 304.3610105268868
; Home run!

1 (user) => (meters-to-feet (travel-distance 1 40 45))

;Value: 269.5039326610774
; Close!

1 (user) => (meters-to-feet (travel-distance 1 35 45))

;Value: 231.99119882455975
; Flyout!!
#+END_SRC

To find out the effect of angle on the travel distance, let we code as follows:
#+BEGIN_SRC scheme
(define (iterate-on-angle method)
  (lambda (velocity elevation)
    (define upper-bound 90)
    (define increment 1)
    (define (next ang) (+ ang increment))
    (define (iter angle max-dist max-ang)
      (if (> angle upper-bound)
          max-ang
          (let ((dist (method elevation velocity angle)))
            (let ((next-ang (next angle)))
              (if (> dist max-dist)
                  (iter next-ang dist angle)
                  (iter next-ang max-dist max-ang))))))
    (iter 0 0 0)))
#+END_SRC
What is generalized =find-best-angle=. We can rewrite =find-best-angle= as
#+BEGIN_SRC scheme
(define find-best-angle
  (iterate-on-angle travel-distance-simple))
#+END_SRC

Back to our task, now we can estimate described effect using:
#+BEGIN_SRC scheme
(define test-effect-of-angle-and-best-angle
  (iterate-on-angle (lambda (elevation velocity angle)
                      (let ((distance (travel-distance elevation velocity angle)))
                        (if (homerun? distance)          ;display result
                            (begin (newline)
                                   (display "Angle (degrees) : ")
                                   (display angle)
                                   (display "\tdistance (meters) : ")
                                   (display distance)
                                   (display "\t(feets) : ")
                                   (display (meters-to-feet distance))))
                        distance))))

(define (homerun? distance)
  (> (meters-to-feet distance) 300))
#+END_SRC
which display each angle with travel distance that let the ball land over the
fence:
#+BEGIN_SRC scheme
1 (user) => (test-effect-of-angle-and-best-angle 45 1)

Angle (degrees) : 31	distance (meters) : 91.51532072764736	(feets) : 302.00055840123633
Angle (degrees) : 32	distance (meters) : 92.06394866247652	(feets) : 303.81103058617254
Angle (degrees) : 33	distance (meters) : 92.68907465558765	(feets) : 305.87394636343925
Angle (degrees) : 34	distance (meters) : 93.0990652827013	(feets) : 307.2269154329143
Angle (degrees) : 35	distance (meters) : 93.4412381854694	(feets) : 308.35608601204905
Angle (degrees) : 36	distance (meters) : 93.5813025098057	(feets) : 308.8182982823588
Angle (degrees) : 37	distance (meters) : 93.79053827815333	(feets) : 309.508776317906
Angle (degrees) : 38	distance (meters) : 93.93134422944617	(feets) : 309.9734359571724
Angle (degrees) : 39	distance (meters) : 93.8787236285791	(feets) : 309.799787974311
Angle (degrees) : 40	distance (meters) : 93.76322959233745	(feets) : 309.4186576547136
Angle (degrees) : 41	distance (meters) : 93.70356375240091	(feets) : 309.22176038292304
Angle (degrees) : 42	distance (meters) : 93.45847229577446	(feets) : 308.4129585760557
Angle (degrees) : 43	distance (meters) : 93.1494935264519	(feets) : 307.3933286372913
Angle (degrees) : 44	distance (meters) : 92.66568484432294	(feets) : 305.7967599862657
Angle (degrees) : 45	distance (meters) : 92.23060925057175	(feets) : 304.3610105268868
Angle (degrees) : 46	distance (meters) : 91.73050392599892	(feets) : 302.7106629557964
Angle (degrees) : 47	distance (meters) : 91.06247282999192	(feets) : 300.50616033897336
;Value: 38
#+END_SRC

So it conclude that if the batter swings the bat at about 100 mph (or 45 m/s),
homerun angle range would be 31 \to 47 degrees; best angle with given situation
is 38 degrees.

If it were Denver, i.e.
#+BEGIN_SRC scheme
;; (define density 1.25)  ; kg/m^3
(define density 1.06)  ; for denver
#+END_SRC

Then the same test results in
#+BEGIN_SRC scheme
1 (user) => (test-effect-of-angle-and-best-angle 45 1)

Angle (degrees) : 25	distance (meters) : 91.80757292364773	(feets) : 302.9649906480375
Angle (degrees) : 26	distance (meters) : 93.23537186687204	(feets) : 307.6767271606778
Angle (degrees) : 27	distance (meters) : 94.39458365678752	(feets) : 311.5021260673988
Angle (degrees) : 28	distance (meters) : 95.47489744142004	(feets) : 315.06716155668613
Angle (degrees) : 29	distance (meters) : 96.6491018216814	(feets) : 318.9420360115486
Angle (degrees) : 30	distance (meters) : 97.5677682297549	(feets) : 321.9736351581912
Angle (degrees) : 31	distance (meters) : 98.24273978796408	(feets) : 324.2010413002815
Angle (degrees) : 32	distance (meters) : 99.00759192365273	(feets) : 326.725053348054
Angle (degrees) : 33	distance (meters) : 99.69345769019637	(feets) : 328.988410377648
Angle (degrees) : 34	distance (meters) : 100.14639278028076	(feets) : 330.4830961749265
Angle (degrees) : 35	distance (meters) : 100.5271971345883	(feets) : 331.73975054414143
Angle (degrees) : 36	distance (meters) : 100.98266355990877	(feets) : 333.24278974769896
Angle (degrees) : 37	distance (meters) : 101.21502833182811	(feets) : 334.0095934950328
Angle (degrees) : 38	distance (meters) : 101.3744208976632	(feets) : 334.53558896228856
Angle (degrees) : 39	distance (meters) : 101.3233691316595	(feets) : 334.36711813447636
Angle (degrees) : 40	distance (meters) : 101.33908658868884	(feets) : 334.4189857426732
Angle (degrees) : 41	distance (meters) : 101.28079791925339	(feets) : 334.22663313353615
Angle (degrees) : 42	distance (meters) : 101.02041185502884	(feets) : 333.3673591215952
Angle (degrees) : 43	distance (meters) : 100.69139652226286	(feets) : 332.28160852346747
Angle (degrees) : 44	distance (meters) : 100.29330967725063	(feets) : 330.9679219349271
Angle (degrees) : 45	distance (meters) : 99.82569987946395	(feets) : 329.42480960223105
Angle (degrees) : 46	distance (meters) : 99.28810645473736	(feets) : 327.6507513006333
Angle (degrees) : 47	distance (meters) : 98.680059495752	(feets) : 325.64419633598163
Angle (degrees) : 48	distance (meters) : 97.89056434436357	(feets) : 323.0388623363998
Angle (degrees) : 49	distance (meters) : 97.14303748827358	(feets) : 320.57202371130285
Angle (degrees) : 50	distance (meters) : 96.21859535764192	(feets) : 317.52136468021837
Angle (degrees) : 51	distance (meters) : 95.2272364727326	(feets) : 314.2498803600176
Angle (degrees) : 52	distance (meters) : 94.16843722545231	(feets) : 310.75584284399264
Angle (degrees) : 53	distance (meters) : 93.04166763942294	(feets) : 307.03750321009574
Angle (degrees) : 54	distance (meters) : 91.84639167839042	(feets) : 303.0930925386884
;Value: 38
#+END_SRC

Quite impressive.
** Problem 7: Throwing instead of hitting
Now let's turn this around. Instead of worrying about how far the ball will
carry when hit, suppose we want a robotic fielder that can throw the ball
accurately and efficiently. For this, we want to determine the best angle to
throw the ball at a given velocity in order to reach a target a given distance
away in the shortest amount of time. We will assume the target is at height 0
(i.e. on the ground) -- we could do this for a given height of the target but
we'll assume that our fielders are good at catching things at ground level!

We need to write a procedure (or set or procedures) that use the same
integration idea to accomplish the following:
- Given an *input velocity* and *desired distance* (plus the other parameters
  such as mass of the ball, the beta coefficient, gravity, and the height at
  which the throw was made),
- we want to *try different initial angles* (ranging from -90 to 90 degrees) at
  which to throw.
- If throwing at a particular angle will result in the ball traveling roughly
  the desired distance (up to some error) then we want to find the time it takes
  for the ball to reach the target using this trajectory. (a variation of our
  =integrate= will do)
- Finally, we want to find the trajectory that results in the shortest time,
  given a fixed initial velocity magnitude (a variation of =find-best-angle=
  will do).


Let's do our job; but we need to consider the case that with given velocity the robotic
fielder can not throw specified distance at all. The problem statement suggests
we should return 0 so that we can tell this case from the others

*** A variation of =integrate=
Now we want =integrate= return time also not only distance. If we allowed to use
data structure called pair it is so easy stuff; but we are supposed not to know
any of that here we use higher order function instead of that.

As the termination condition is as same of the batting, all the change we should
make is trace additional integrate variable -- time. To do this we generalize
=integrate= procedure:
#+BEGIN_SRC scheme
(define (intergrate-gen terminate? select)
  (lambda (x0 y0 u0 v0 dt g m beta)
    (define (iter x y u v t)
      (if (terminate? x y u v t)        ;termination condition
          (select x y u v t)
          (let ((speed (sqrt (+ (square u)
                                (square v))))
                (v-factor (* (/ 1 m)
                             beta)))
            (let ((dx (* u dt))
                  (dy (* v dt))
                  (du (* (- v-factor)
                         speed
                         u
                         dt))
                  (dv (* (- (+ (* v-factor
                                  speed
                                  v)
                               g))
                         dt)))
              (iter (+ x dx)            ;transition
                    (+ y dy)
                    (+ u du)
                    (+ v dv)
                    (+ t dt))))))
    (iter x0 y0 u0 v0 0)))

(define integrate                       ;returns x when y becomes negative.
  (integrate-gen
   (lambda (x y u v t) (< y 0))
   (lambda (x y u v t) x)))
#+END_SRC

Then we can use the following to collect the time:
#+BEGIN_SRC scheme
(define (travel-desired-distance-time desired-distance elevation speed angle)
  (let ((epsilon 0.5))                  ;tolerance (m)
    (travel (integrate-gen
             (lambda (x y u v t)
               (or (< y 0)
                   (> x (+ desired-distance epsilon)))) ;termination
             (lambda (x y u v t)
               (if (and (< y 0)
                        (< (abs (- x desired-distance)) epsilon))
                   t                    ;return
                   0))))                ;default value
    elevation speed angle))
#+END_SRC

Well, in this way we broke the abstraction barrier by the very lower procedure,
=travel= procedure to know about when to terminate and what to return; even
more, the default value, which definitely defined at the very higher level of
procedure, thus we should be able to change that value easily and defer the
decision what the value should be.

Also, as we learned that data structure -- pair -- even before the higher order
procedure! So if we are good to use higher order procedure, so does pair!

Let's reflect that fact to our code:
#+BEGIN_SRC scheme
(define (travel method elevation speed angle)
  (let ((alpha (degree2radian angle)))
    (method 0
            elevation
            (* speed
               (cos alpha))
            (* speed
               (sin alpha))
            0.01
            gravity
            mass
            beta)))

(define (travel-distance-with-time elevation speed angle)
  (travel
   (integrate-gen
    (lambda (x y u v t) (< y 0))
    (lambda (x y u v t) (make-dist-time x t)))
   elevation speed angle))

;; wrapper structure
(define (make-dist-time x t) (cons x t))
(define (dist p) (car p))
(define (time p) (cdr p))
#+END_SRC

*** A variation of =find-best-angle=
We modified integration procedure to return the pair of traveled distance and
traveled time. Using this procedure we can find the minimum travel time when we
throw the ball to desired distance:
#+BEGIN_SRC scheme
(define (iterate-on-angle lower upper method update? return)
  (lambda (velocity elevation)
    (define increment 0.1)
    (define (next ang) (+ ang increment))
    (define (iter angle extremum ext-ang)
      (if (>= angle upper)
          (return ext-ang extremum)
          (let ((result (method elevation velocity angle)))
            (let ((next-ang (next angle)))
              (if (update? result extremum)
                  (iter next-ang result angle)
                  (iter next-ang extremum ext-ang))))))
    (iter lower 0 0)))

(define (throw-desired-distance velocity desired-distance height)
  (let ((epsilon 0.5))                  ;distance tolerance (m)
    ((iterate-on-angle
      -90                               ;lower bound angle
      90                                ;upper bound angle
      (lambda (elevation velocity angle)
        (let ((result (travel-distance-with-time elevation velocity angle))) ;distance-time pair
          (if (< (abs (- (dist result) desired-distance)) epsilon)           ;within tolerance?
              (time result)                                                  ;return that time
              0)))                                                           ;return default time
      (lambda (current min)                                                  ;update condition
        (and (not (zero? current))
             (or (zero? min)
                 (< current min))))
      cons)                             ;construct pair that contains angle with minimum travel time
     velocity height)))                 ;initial velocity and height at which the throw made
#+END_SRC

**** With these procedure we can determine the required question: If our catcher has
a gun for an arm, and can throw at 100 mph (or 45 m/s), how long does it take to
reach second base (about 36 m apart from home plate)? How long if he throws at
35 m/s? of at 55 m/s?

Results:
#+BEGIN_SRC scheme
1 (user) => (throw-desired-distance 45 36 1)

;Value: (4.3999999999991655 . .9300000000000006)

1 (user) => (throw-desired-distance 35 36 1)

;Value: (8.399999999999151 . 1.1900000000000008)

1 (user) => (throw-desired-distance 55 36 1)

;Value: (2.399999999999165 . .7600000000000005)
#+END_SRC

The =car= of returned is angle at which the minimum time made, the =cdr= of it
is that minimum time.

**** Note that a really good base runner should be able to get from first to second
base in roughly 3 seconds. If the pitcher is throwing at 90 mph how long does it
take to reach home? If the catcher throws at 90 mph, how much time does he have
to catch and release the ball if he is going to put out a runner trying to steal
second?

Since 90 mph is approximately equals to 40 m/s and the whole distance the ball
travel is about 18 + 36 m, we can estimate what we requested as follows:
#+BEGIN_SRC scheme
1 (user) => (throw-desired-distance 40 18 1)

;Value: (-8.35914670815896e-13 . .47000000000000025)

1 (user) => (throw-desired-distance 40 36 1)

;Value: (5.89999999999916 . 1.0300000000000007)
#+END_SRC

So, the catcher should catch and release the ball in 1.5 seconds.
**** Now we estimate the outfielders.
Suppose an outfielder has a strong arm and can throw at 45 m/s. How quickly can
he throw the ball to a target at a distance of 30m? 60m? 80m? What if he can
throw 55 m/s?

Here is the result:
#+BEGIN_SRC scheme
1 (user) => (throw-desired-distance 45 30 1.8)

;Value: (1.1999999999991642 . .7400000000000004)

1 (user) => (throw-desired-distance 45 60 1.8)

;Value: (10.099999999999145 . 1.7300000000000013)

1 (user) => (throw-desired-distance 45 80 1.8)

;Value: (17.499999999999144 . 2.5899999999999888)

1 (user) => (throw-desired-distance 55 30 1.8)

;Value: (-.30000000000083593 . .6100000000000003)

1 (user) => (throw-desired-distance 55 60 1.8)

;Value: (5.99999999999916 . 1.390000000000001)

1 (user) => (throw-desired-distance 55 80 1.8)

;Value: (10.699999999999143 . 2.0500000000000003)
#+END_SRC

With a weaker outfielder, the same distance results into
#+BEGIN_SRC scheme
1 (user) => (throw-desired-distance 35 30 1.8)

;Value: (4.3999999999991655 . .9600000000000006)

1 (user) => (throw-desired-distance 35 60 1.8)

;Value: (18.999999999999165 . 2.3099999999999947)

1 (user) => (throw-desired-distance 35 80 1.8)

;Value: (0 . 0)
#+END_SRC

This outfielder can not throw the ball to the distance apart 80 m from where the
throw made.
*** Reconsider
We quite struggled to get fitted our task to newly constructed framework that we
generalized. We did that since we know that it decomposes monolithic procedures
into several procedures, each of which are general enough to do have meaning
what they are computing. This concept was supposed to be dealt with in the next
project -- not here. Actually our problem statement also implies this fact -- it
guides us to write procedures by explanatory description of algorithm informally.

Here we follow that step not to be obsessed by clever implementing. Here is the
informal algorithm we are going to code:
1. Take velocity, desired distance, etc for formal parameter our whole
   procedure -- i.e. as entry point.
2. For each angle \in $[-90, 90]$, integrate whose termination condition is $(x
   > \text{desired distance})~or~(y < 0)$
   , which means terminate integral whenever our throwing turns out to overshoot the target
   or hit the ground.
3. For updating step of integration, we call another procedure if the
   termination condition satisfy given situation:
   If ($x$ in the range -- desired distance \pm tolerance) then if $t$ is less
   than the minimum time being searched so far, update the minimum time with the
   corresponding angle (we can do this by calling outermost loop with updated
   minimum time and angle).
4. If the loop end by exceeding the upper limit of angle (90 degrees in our
   case), return the minimum time (as we will set the initial minimum time
   traveled as 0, so if there is not any trajectory that can reach the desired
   distance then it would return 0 as default value).


Here is the result:
#+BEGIN_SRC scheme
(define (throw-desired-distance velocity desired-distance height)
  (define tolerance 0.5)                ;tolerance 0.5m
  (define upper-limit 90)
  (define lower-limit -90)
  (define increment 0.1)
  (define (next ang) (+ ang increment))
  (define (loop angle minimum-time minimum-angle)
    (if (> angle upper-limit)
        minimum-time
        (integrate-and-update angle minimum-time minimum-angle)))
  (define (integrate-and-update angle minimum-time minimum-angle)
    (define (throw-desired-distance velocity desired-distance height)
  (define tolerance 0.5)                ;tolerance 0.5m
  (define upper-limit 90)
  (define lower-limit -90)
  (define increment 0.1)
  (define (next ang) (+ ang increment))
  (define (loop angle minimum-time minimum-angle)
    (if (> angle upper-limit)
        minimum-time
        (integrate-and-update angle minimum-time minimum-angle)))
  (define (integrate-and-update angle minimum-time minimum-angle)
    (define (in-range? x) (< (abs (- desired-distance x)) tolerance))
    (define (hit-ground? y) (< y 0))
    (define (overshoot? x) (> x (+ desired-distance tolerance)))
    (define integrate (lambda (x0 y0 u0 v0 dt g m beta)
                        (define (iter x y u v t)
                          (if (or (hit-ground? y)
                                  (overshoot? x))   ;termination condition
                              (if (and (in-range? x)
                                       (or (zero? minimum-time)
                                           (< t minimum-time)))
                                  (loop (next angle) t angle)
                                  (loop (next angle) minimum-time minimum-angle))
                              (let ((speed (sqrt (+ (square u)
                                                    (square v))))
                                    (v-factor (* (/ 1 m)
                                                 beta)))
                                (let ((dx (* u dt))
                                      (dy (* v dt))
                                      (du (* (- v-factor)
                                             speed
                                             u
                                             dt))
                                      (dv (* (- (+ (* v-factor
                                                      speed
                                                      v)
                                                   g))
                                             dt)))
                                  (iter (+ x dx) ;transition
                                        (+ y dy)
                                        (+ u du)
                                        (+ v dv)
                                        (+ t dt))))))
                        (iter x0 y0 u0 v0 0)))
    (let ((alpha (degree2radian angle)))
      (integrate 0
                 height
                 (* velocity
                    (cos alpha))
                 (* velocity
                    (sin alpha))
                 0.01
                 gravity
                 mass
                 beta)))
  (loop lower-limit 0 0))
#+END_SRC

And the tests:
#+BEGIN_SRC scheme
1 (user) => (throw-desired-distance 45 30 1.8)

;Value: .7400000000000004

1 (user) => (throw-desired-distance 45 60 1.8)

;Value: 1.7300000000000013

1 (user) => (throw-desired-distance 45 80 1.8)

;Value: 2.5899999999999888
#+END_SRC

Finally we can decomposes this monolith by recognizing the duplicative codes:
#+BEGIN_SRC scheme
(define (throw-desired-distance velocity desired-distance height)
  (define tolerance 0.5)                ;tolerance 0.5m
  (define upper-limit 90)
  (define lower-limit -90)
  (define increment 0.1)
  (define (next ang) (+ ang increment))
  (define (loop angle minimum-time minimum-angle)
    (if (> angle upper-limit)
        minimum-time
        (integrate-and-update angle minimum-time minimum-angle)))
  (define (integrate-and-update angle minimum-time minimum-angle)
    (define (in-range? x) (< (abs (- desired-distance x)) tolerance))
    (define (hit-ground? y) (< y 0))
    (define (overshoot? x) (> x (+ desired-distance tolerance)))
    (define integrate
      (integrate-gen
       (lambda (x y u v t) (or (hit-ground? y)
                               (overshoot? x)))
       (lambda (x y u v t)
         (if (and (in-range? x)
                  (or (zero? minimum-time)
                      (< t minimum-time)))
             (loop (next angle) t angle)
             (loop (next angle) minimum-time minimum-angle)))))
    (travel integrate height velocity angle)) ;initial condition setter
  (loop lower-limit 0 0))
#+END_SRC

We could decompose further by generalizing the loop procedure of
=iterate-on-angle=; but I found it would rather make readability of our code
worse. Now, our code get concise enough to be readable yet maintain the
structure of described algorithm above. Also we didn't rely on the data
structure -- pair.
** Problem 8: Do it on a bounce
We noticed from preceding problem that weak outfielders can not get the ball
more than 80m in the air. So he may have to bounce it there. Let's model this
effect.

Specifically, assume that when a ball bounces, it leaves the ground at the same
angle as it was initially thrown (untrue but a reasonable approximation) but
with half the velocity. Our task is to write a procedure that will determine the
distance traveled, accounting for drag, given an initial velocity, an angle of
throw, an initial height, and the number of bounces it will take.

Here is the algorithm we are going to code:
1. Set initial condition.
2. Using =travel-distance= determine traveled distance with no bound and increment
   =sum-dist= by the result of =travel-distance=.
3. If remaining bounce is zero then terminate the loop with =sum-dist=.
4. Else set velocity to half of it and set height to 0.
5. Iterate on 2 \to 4.


Here is the resulting straightforward code:
#+BEGIN_SRC scheme
(define (travel-distance-with-bounces elevation speed angle bounces)
  (define (iter vel remaining-bounces sum-dist)
    (if (zero? remaining-bounces)
        sum-dist
        (iter (/ vel 2.) (1- remaining-bounces)
              (+ sum-dist (travel-distance 0 vel angle)))))
  (iter (/ speed 2.) bounces (travel-distance elevation speed angle)))
#+END_SRC

And here is the test:
#+BEGIN_SRC scheme
1 (user) => (travel-distance-with-bounces 1.8 35 19 3)

;Value: 83.39858829506251
#+END_SRC

Now our outfielder who has weak shoulder can throw the ball to reach apart 80m.

Let we do the case of an arbitrary number of bounces until it stops moving. We
exploit the same strategy of previous problem in robotic fielder -- using error
tolerance for the decision whether the ball stopped.

We can do that by slightly amending the code of fixed numbered bounces version:
By changing the termination condition to /vel < tolerance/:
#+BEGIN_SRC scheme
(define (travel-distance-with-arbitrary-bounces elevation speed angle)
  (define (stop? vel) (< vel .1))
  (define (iter vel sum-dist)
    (if (stop? vel)
        sum-dist
        (iter (/ vel 2.)
              (+ sum-dist (travel-distance 0 vel angle)))))
  (iter (/ speed 2.) (travel-distance elevation speed angle)))
#+END_SRC

Here is the test:
#+BEGIN_SRC scheme
1 (user) => (travel-distance-with-arbitrary-bounces 1.8 35 19)

;Value: 83.8583448733793
#+END_SRC

Unfortunately, our weak outfielders cannot throw the ball to reach to the place
90m apart. It is quite different from the strong outfielders:
#+BEGIN_SRC scheme
1 (user) => (travel-distance-with-arbitrary-bounces 1.8 45 19)

;Value: 120.78963743871626
#+END_SRC
** Problem 9: Do it on a bounce -- again
In Problem 8, we just assumed that the velocity would drop by one half on each
bounce. But in fact we are integrating trajectories in order to account for
drag, we can actually compute the velocity of the ball when it bounces (since we
know the $x$ and $y$ components of velocity when the ball hits the ground).
Using our previous general integration procedure we can easily implement what we
should do:
1. Set the termination condition of the integration to =hits-ground?= as
   previous; but we use this condition as transition to bounce.
2. Set the selection of the integration to if =(stop? vel)= then terminate
   ultimately -- return the $x$ component, else invert the sign of $v$ component
   then continue the iteration (actually to support this code we need to amend
   the =integrate-gen= to pass =iter= to the parameter of =select=).


First, we implement the arbitrary number bounces version:
#+BEGIN_SRC scheme
(define (integrate-gen terminate? select)
  (lambda (x0 y0 u0 v0 dt g m beta)
    (define (iter x y u v t)
      (if (terminate? x y u v t)        ;termination condition
          (select x y u v t iter)
          (let ((speed (sqrt (+ (square u)
                                (square v))))
                (v-factor (* (/ 1 m)
                             beta)))
            (let ((dx (* u dt))
                  (dy (* v dt))
                  (du (* (- v-factor)
                         speed
                         u
                         dt))
                  (dv (* (- (+ (* v-factor
                                  speed
                                  v)
                               g))
                         dt)))
              (iter (+ x dx)            ;transition
                    (+ y dy)
                    (+ u du)
                    (+ v dv)
                    (+ t dt))))))
    (iter x0 y0 u0 v0 0)))

(define (travel-distance-with-arbitrary-bounces2 elevation speed angle)
  (define (hits-the-ground? y) (< y 0))
  (define (stop? vel) (< (abs vel) .1))
  (define integrate
    (integrate-gen
     (lambda (x y . rest) (hits-the-ground? y))
     (lambda (x y u v t iter)
       (if (begin (newline) (display v) (stop? v)) x
           (iter x y u (- v) t)))))
  (travel integrate elevation speed angle))
#+END_SRC

Unfortunately, this doesn't work:
#+BEGIN_SRC scheme
1 (user) => (travel-distance-with-arbitrary-bounces2 1.8 45 19)

-12.888754064178412
12.888754064178412
-12.888754064178412
12.888754064178412
-12.888754064178412
12.888754064178412
-12.888754064178412
...
#+END_SRC

The problem was the termination condition works immediately after we invert =v=
as the =y= is less than 0. So we set the =y= to 0 to fix this:
#+BEGIN_SRC scheme
1 (user) => (travel-distance-with-arbitrary-bounces2 1.8 45 19)

-12.888754064178412
-11.453707821293339
-10.59153109045374
...
-7.104654040674966
-7.104654040675094
-7.104654040674973
-7.104654040675086
;Quit!
#+END_SRC
We fixed our original bug but encountered with another: After experimenting with
the debug code, that is, to change display x not v, we got:
#+BEGIN_SRC scheme
1 (user) => (travel-distance-with-arbitrary-bounces2 1.8 45 19)

82.68319955602507
126.84863975747217
...
379.04242193941747
379.04242193941747
379.04242193941747
;Quit!
#+END_SRC

That is, it indicates that we should use =u= to determine whether the ball
stopped. The reason behind of this is that our drag affect on primarily to velocity
of x component. Then rerun our test:
#+BEGIN_SRC scheme
1 (user) => (travel-distance-with-arbitrary-bounces2 1.8 45 19)

;Value: 361.2999476708538

1 (user) => (travel-distance-with-arbitrary-bounces2 1.8 35 19)

;Value: 338.6223063509878
#+END_SRC

This produces huge difference from the previous calculation: It is mainly due to the
fact that we modeled the bounce as elastic collision, which is not certainly
true.

Now let's turn to the fixed numbered bounces case. To do this, we should hand
over the =bounces= state variable to our integration method to keep track of
that. To make our general integration procedure make this happen, we should
amend that or make another procedure that manipulate state variable:
#+BEGIN_SRC scheme
(define (travel-distance-with-bounces2 elevation speed angle bounces)
  (define (hits-the-ground? y) (< y 0))
  (define (loop remaining-bounces x y u v)
    ((integrate-gen
      (lambda (x y . rest) (hits-the-ground? y))
      (lambda (x y u v . rest)
        (if (zero? remaining-bounces) x ;return accumulated distance
            (loop (-1+ remaining-bounces) x 0 u (- v)))))
     x y u v 0.01 gravity mass beta))   ;intermediate state variables
  (let ((alpha (degree2radian angle)))
    (loop bounces 0 elevation           ;initial condition
          (* speed (cos alpha))
          (* speed (sin alpha)))))
#+END_SRC

Then let's test:
#+BEGIN_SRC scheme
1 (user) => (travel-distance-with-bounces2 1.8 35 19 3)

;Value: 144.40112681673043

1 (user) => (travel-distance-with-bounces2 1.8 35 19 2)

;Value: 123.89518783211233

1 (user) => (travel-distance-with-bounces2 1.8 35 19 1)

;Value: 97.3312222038267

1 (user) => (travel-distance-with-bounces2 1.8 35 19 0)

;Value: 59.61469931243074
#+END_SRC
* Project 2 -- Prisoner's Dilemma
** Purpose
Project 2 focuses on the use of higher order procedures. together with data
structures. We will also further develop and demonstrate our ability to write
clear, intelligible, well-documented procedures, as well as text cases for our
procedures.
** A Fable
In the mid-1920's, the Nebraska State Police achieved what may still be their
finest moment. After a 400-mile car chase over dirt roads and through corn
fields, they finally caught up with the notorious bank robbers Bunny and Clod.
The two criminals were brought back to the police station in Omaha for further
interrogation. Bunny and Clod were questioned in separate rooms, and each was
offered the same deal by the police. The deal went as follows (since both are
the same, we need only describe the version presented to Bunny):

#+BEGIN_QUOTE
"Bunny, Here's the offer that we are making to both you and Clod. If you both
hold out on us and don't confess to bank robbery, then we admit that we don't
have enough proof to convict you. However, we will be able to jail you both for
one year, for reckless driving and endangerment of corn. If you turn state's
witness and help us convict Clod (assuming he doesn't confess) , then you will
go free, and Clod will get twenty years in prison. On the other hand, if you
don't confess and Clod does, then *he* will go free and *you* will get twenty years."

"What happens if both Clod and I confess?" asked Bunny.

"Then you both get ten years," responded the police.
#+END_QUOTE

Bunny, who had been a math major at Cal Tech before turning to crime, reasoned
this way:
#+BEGIN_QUOTE
"Suppose Clod intends to confess. Then if I don't confess, I'll get twenty
years, but if I do confess, I'll only get ten years. On the other hand, suppose
Clod intends to hold out on the cops. Then if I don't confess, I'll go to jail
for a year, but if I do confess, I'll go free. So no matter what Clod intends to
do, I am better off confessing than holding out. So I'd better confess."
#+END_QUOTE

Naturally, Clod employed the very same reasoning. Both criminals confessed, and
both went to jail for ten years (Well, actually they didn't go to jail. When
they were in court, and heard that thy had both turned state's witness, they
strangled each other. But that's another story.) The police, of course, were
triumphant, since the criminals would have been free in a year bad both remained
silent.
** The Prisoner's Dilemma
The Bunny and Clod story is an example of a situation known in mathematical game
theory as the "prisoner's dilemma." A prisoner's dilemma always involves two
"game players," and each has a choice between "cooperating" and "defecting." If
the two players cooperate, they each do moderately well; if they both defect,
they each do moderately poorly. If one player cooperates and the other defects,
then the defector does  extremely well and the cooperator does extremely poorly.
(In the case of the Bunny and Clod story, "cooperating" means cooperating with
one's partner -- i.e. holding out on the police -- and  "defecting" means
confessing to bank robbery.) Before formalizing the prisoner's dilemma
situation, we need to introduce some basic game theory notation.
** A Crash Course in Game Theory
In game theory, we differentiate between a /game/, and a /play/. A /game/ refers
to the set of possible choices and outcomes for the entire range of situations.
A /play/ refers to a specific set of choices by the players, with the associated
outcome for that particular scenario. Thus, in game theory, a /two-person
binary-choice game/ is represented by two-by-two matrix. Here is a hypothetical
game matrix:
|                | *B* cooperates | *B* defects |
|----------------+----------------+-------------|
| *A* cooperates | *A* gets 5     | *A* gets 2  |
|                | *B* gets 5     | *B* gets 3  |
|----------------+----------------+-------------|
| *A* defects    | *A* gets 3     | *A* gets 1  |
|                | *B* gets 2     | *B* gets 1  |

The two players in this case are called *A* and *B*, and the choices are called
"cooperate" and "defect." Players *A* and *B* can play a single game by
separately (and secretly) choosing either to cooperate or to defect. Once each
player has made a choice, he announces it to the other player; and the two then
look up their respective scores in the game matrix. Each entry in the matrix is
a pair of numbers indicating a score for each player, depending on their
choices. Thus, in the example above, if Player *A* chooses to cooperate while
Player *B* defects, then *A* gets 2 points and *B* gets 3 points. If both
players defect, they each get 1 point. Note, by the way, that the game matrix is
a matter of public knowledge; for instance, Player *A* knows before the game
even starts that if he and *B* both choose to defect, they will each get 1
point.

In an /iterated game/, the two players play repeatedly; thus after finishing one
game, *A* and *B* may play another. (Admittedly, there is a little confusion in
the terminology here; thus we refer to each iteration as a "play," which
constitutes a single "round" of the larger, iterated game.) There are a number
of ways in which iterated games may be played; in the simplest situation, *A*
and *B* play for some fixed number of rounds (say 200), and before each round,
they are able to look at the record of all previous rounds. For instance, before
playing the tenth round of their iterated game, both *A* and *B* are able to
study the results of the previous nine rounds.
** An Analysis of a Simple Game Matrix
The game depicted by the matrix above is a particularly easy one to analyze.
Let's examine the situation from Player *A*'s point of view (Player *B*'s point
of view is identical):

#+BEGIN_QUOTE
"Suppose *B* cooperates. Then I do better by cooperating myself (I receive five
points instead of three). On the other hand, suppose *B* defects. I still do
better by cooperating (since I get two points instead of one). So no matter what
*B* does, I am better off cooperating."
#+END_QUOTE

Player *B* will, of course, reason the same way, and both will choose to
cooperate. In the terminology of game theory, both *A* and *B* have a /dominant/
choice -- i.e., a choice that gives a preferred outcome no matter what the other
player chooses to do. The matrix shown above, by the way, does /not/ represent a
prisoner's dilemma situation, since when both players make their dominant
choice, they also both achieve their highest personal scores. We'll see an
example of a prisoner's dilemma game very shortly.

*To re-cap:* in any particular game using the above matrix, we would expect both
 players to cooperate; and in an iterated game, we would expect both players to
 cooperate repeatedly, on every round.
** The Prisoner's Dilemma Game Matrix
Now consider the following game matrix:
|                | *B* cooperates | *B* defects |
|----------------+----------------+-------------|
| *A* cooperates | *A* gets 3     | *A* gets 0  |
|                | *B* gets 3     | *B* gets 5  |
|----------------+----------------+-------------|
| *A* defects    | *A* gets 5     | *A* gets 1  |
|                | *B* gets 0     | *B* gets 1  |

In this case, Players *A* and *B* both have a dominant choice -- namely,
defection. No matter what Player *B* does, Player *A* improves his own score by
defecting, and vice versa.

However, there is something odd about this game. It seems as through the two
players would benefit by choosing to cooperate. Instead of winning only one
point each, they could win three points each. So the "rational" choice of mutual
defection has a puzzling self-destructive flavor.

The second matrix is an example of a prisoner's dilemma game situation. Just to
formalize the situation, let $CC$ be the number of points won by each player
when they both cooperate; let $DD$ be the number of points won when both defect;
let $CD$ be the number of points won by the cooperating party when the other
defects, and let $DC$ be the number of points won by the defecting party when
the other cooperates. Then the prisoner's dilemma situation is characterized by
the following conditions:
\begin{align*}
DC > CC &> DD > CD\\
CC &> \frac{DC + CD}{2}
\end{align*}

In the second game matrix, we have
\[DC = 5,\quad CC = 3,\quad DD = 1,\quad CD = 0\]
so both conditions are met. In the Bunny and Clod story, by the way, you can
verify that:
\[DC = 0,\quad CC= -1,\quad DD = -10,\quad CD = -20\]
Again, these values satisfy the prisoner's dilemma conditions.
** Axelrod's Tournament
In the late 1970's, political scientist Robert Axelrod held a computer
tournament designed to investigate the prisoner's dilemma situation (Actually,
there were two tournaments. Their rules and results are described in Axelrod's
book: /The Evaluation of Cooperation/.). Contestants in the tournament submitted
computer programs that would compete in an iterated prisoner's dilemma game of
approximately two hundred rounds, using the second matrix above. Each
contestant's program played five iterated games against each of the other
programs submitted, and after all games had been played the scores were tallied.

The contestants in Axelrod's tournament included professors of political
science, mathematics, computer science, and economics. The winning program --
the program with the highest average score -- was submitted by Anatol Rapoport,
a professor of psychology at the University of Toronto. In this project, we will
pursue Axelrod's investigations and make up our own Scheme programs to play the
iterated prisoner's dilemma game.

As part of this project, we will be running a similar tournament, but now
involving a three-person prisoner's dilemma.

Before we look at the two-player program, it is worth speculating on what
possible strategies might be employed in the iterated prisoner's dilemma game.
Here are some examples:

- Nasty :: a program using the *Nasty* strategy simply defects on every round of
     every game.
- Patsy :: a program using the *Pasty* strategy cooperates on every round of
     every game.
- Spastic :: this program cooperates or defects on a random basis.
- Egalitarian :: this program cooperates on the first round. On all subsequent
     rounds, *Egalitarian* examines the history of the other player's actions,
     counting the total number of defections and cooperations by the other
     player. If the other player's defections outnumber her cooperations,
     *Egalitarian* will defect; otherwise this strategy will cooperate.
- Eye-for-Eye :: this program cooperates on the first round, and then on every
     subsequent round it mimics the other player's previous move. Thus, if the
     other player cooperates (defects) on the /n/th round, then *Eye-for-Eye*
     will cooperate (defect) on the (/n/+1)st round.


All of these strategies are extremely simple. (Indeed, the first three do not
even pay any attention to the other player; their responses are uninfluenced by
the previous rounds of the game.) Nevertheless, simplicity is not necessarily a
disadvantage. Rapoport's first-prize program employed the *Eye-for-Eye*
strategy, and achieved the highest average score in a field of far more
complicated programs.
** The Two-Player Prisoner's Dilemma Program
A Scheme program for an iterated prisoner's dilemma game is provided as part of
the code for this project. The procedure =play-loop= pits two players (or, to be
more precise, two "strategies") against one another for approximately 100 games,
then prints out the average score of each player.

Player strategies are represented as procedures. Each strategy takes two inputs
-- its own "history" (that is, a list of all its previous "plays," where for
convenience we will use "c" to represent cooperate, and "d" to represent defect)
and its opponent's "history." The strategy returns either the string "c" for
"cooperate" or the string "d" for "defect." (Note that we will need to use
procedures appropriate for comparing strings when we analyze these results.)

At the beginning of an iterated game, each history is an empty list. As the game
progresses, the histories grow (via =extend-history=) into lists of "=c="'s and
"=d="'s, thus each history is stored from most recent to least recent. Note how
each strategy must have its /own/ history as its first input. So in
=play-loop-iter,strat0= has =history0= as its first input, and =strat1= has
=history1= as its first input.

The values from the game matrix are stored in a list named
=*game-association-list*=. This list is used to calculate the scores at the end
of the iterated game.
#+BEGIN_SRC scheme
(define *game-association-list*
  '((("c" "c") (3 3))
    (("c" "d") (0 5))
    (("d" "c") (5 0))
    (("d" "d") (1 1))))
#+END_SRC

Thus, if both players cooperate, the payoff to each player is a 3, if one player
cooperates and the other defects, the defecting player gets a payoff of 5, the
cooperating player gets a zero payoff, if both players defect, each gets a
payoff of 1.

Some sample strategies are given in the code. =Nasty= and =Patsy= are
particularly simple; each returns a constant value regardless of the histories.
=Spastic= also ignores the histories and chooses randomly between cooperation
and defection. We should study =Egalitarian= and =Eye-for-Eye= to see that their
behavior is consistent with the descriptions in the previous section.
** Problem 1
To be able to test out the system, we need to complete a definition for
=extract-entry=. This procedure will retrieve the payoff information from the
game association list. The procedure's behavior is as follows: it takes as input
a play, represented as a list of choices for each strategy (i.e., a "c" or a
"d"), and the game association list. Thus a play will in this case be a list of
two entries (since there are two players), each of which is the choice of action
for that player. Each entry in the game association list is a list itself, with
a first element representing a list of game choices, and the second element
representing a list of scores (or payoffs) for each player. Thus =extract-entry=
wants to search down the game association list trying to match its first
argument against the first element of each entry in the game association list,
one by one. When it succeeds, it returns that whole entry.

For example, we expect the following behavior:
#+BEGIN_SRC scheme
(define a-play (make-play "c" "d"))

;Value: a-play

(extract-entry a-play *game-association-list*)

;Value: (("c" "d") (0 5))
#+END_SRC

It is easy stuff to do: Even though I've got worse condition, could implement
this:
#+BEGIN_SRC scheme
(define (extract-entry play game-assc-list)
  (cond ((null? game-assc-list)
         (error "No matching error: There is no such play -- EXTRACT-ENTRY" play))
        ((equal? play (caar game-assc-list))
         (car game-assc-list))
        (else (extract-entry play (cdr game-assc-list)))))
#+END_SRC

Here is extra tests:
#+BEGIN_SRC scheme
1 (user) => (define b-play (make-play "c" "c"))

;Value: b-play

1 (user) => (extract-entry b-play *game-association-list*)

;Value: (("c" "c") (3 3))

1 (user) => (extract-entry (make-play "d" "d") *game-association-list*)

;Value: (("d" "d") (1 1))

1 (user) => (extract-entry (make-play "d" "c") *game-association-list*)

;Value: (("d" "c") (5 0))
#+END_SRC

We exploited the =equal= procedure that can compare list structure element-wise.
** Problem 2
Use =play-loop= to play games among the five defined strategies. Notice how a
strategy's performance varies sharply depending on its opponent. For example,
=Patsy= does quite well against =Eye-for-Eye= or against another =Patsy=, but it
loses badly to =Nasty=. Pay special attention to =Eye-for-Eye=. Notice how it
never eats its opponent -- but it never loses badly. Create a matrix in which
you show the average score for tournaments pitting all possible pairings of the
five different strategies: =Nasty=, =Patsy=, =Eye-for-Eye=, =Spastic=,
=Egalitarian=. Describe the behavior you observe for the different strategies.

Here is the matrix requested:
|               | =Nasty=         | =Patsy=                  | =Eye-for-Eye=  | =Spastic=                | =Egalitarian=  |
|---------------+-----------------+--------------------------+----------------+--------------------------+----------------|
| =Nasty=       | (1., 1.)        | (5., 0)                  | (1.04, .99)    | (2.684, .579)            | (1.038, .990)  |
| =Patsy=       | (0, 5.)         | (3., 3.)                 | (3., 3.)       | (1.412, 4.059)           | (3., 3.)       |
| =Eye-for-Eye= | (.9897, 1.0412) | (3., 3.)                 | (3., 3.)       | (2.2\dot{8}, 2.2\dot{8}) | (3., 3.)       |
| =Spastic=     | (.523, 2.907)   | (3.9\dot{7}, 1.5\dot{3}) | (2.209, 2.209) | (2.105, 2.248)           | (1.478, 2.239) |
| =Egalitarian= | (.9902, 1.0392) | (3., 3.)                 | (3., 3.)       | (1.71, 3.86)             | (3., 3.)       |

And the average score of each:
| Strategy      | Average score |
|---------------+---------------|
| =Nasty=       |        2.1524 |
| =Patsy=       |        2.0824 |
| =Eye-for-Eye= |       2.45594 |
| =Spastic=     |        2.3331 |
| =Egalitarian= |       2.34004 |

Note that the play between =Spastic= strategy and =Egalitarian=: It results to
win one-side hugely but not fixed -- which one would win is not determined; it
inherit the randomness of =Spastic=. From the average score matrix, we can
verify ourselves that =Eye-for-Eye= strategy got the best score overall -- even
if =Eye-for-Eye= never have won in above plays. Also note that =Nasty= always
win or at least draw the other who matched to play with =Nasty=.

For the other cases, we can observe that =Patsy=, =Eye-for-Eye=, =Egalitarian=
always draw -- cooperate each other, =Spastic= tends to draw with =Eye-for-Eye=
but not with =Egalitarian=.
** Problem 3
Games involving *Egalitarian* tend to be slower than other games. Why is that
so? Use order-of-growth notation to explain our answer.

Let /n/ to be the number of history (it would be same as other history). Then
the step complexity can be deduced as \Theta(n); space complexity is also
\Theta(n). The revised version or iterative version has \Theta(n) as its step
complexity and \Theta(1) space complexity as it is iterative process.

Consequently, the newer version doesn't improved the step complexity in the
terms of order or growth; however the actual time it would take to complete
approximately halved down as now we calculate =cs= and =ds= in a one loop -- not
with separate loop as we did before.
** Problem 4
Write a new strategy =eye-for-two-eyes=. The strategy should always cooperate
unless the opponent defected on both of the previous two rounds. (Looked at
another way: =eye-for-two-eyes= should cooperate if the opponent cooperated on
either of the previous two rounds.) Play =eye-for-two-eyes= against other
strategies. Describe the behavior you observe.

The code is straightforward:
#+BEGIN_SRC scheme
(define (EYE-FOR-TWO-EYE my-history other-history)
  (define (has-history-less-than-2? hist)
    (or (empty-history? hist)
        (empty-history? (rest-of-plays hist))))
  (define (defected-previous-2-rounds? hist)
    (and (string=? (most-recent-play hist) "d")
         (string=? (most-recent-play (rest-of-plays hist)) "d")))
  (cond ((has-history-less-than-2? my-history) "c")
        ((defected-previous-2-rounds? other-history) "d")
        (else                           ;has "c" in previous 2 rounds
         "c")))
#+END_SRC

Here is the observations:
#+BEGIN_SRC scheme
(play-loop nasty eye-for-two-eye)

Player 1 Score:  1.0740740740740742
Player 2 Score:  .9814814814814815

(play-loop patsy eye-for-two-eye)

Player 1 Score:  3.
Player 2 Score:  3.

(play-loop egalitarian eye-for-two-eye)

Player 1 Score:  3.
Player 2 Score:  3.

(play-loop eye-for-eye eye-for-two-eye)

Player 1 Score:  3.
Player 2 Score:  3.

(play-loop spastic eye-for-two-eye)

Player 1 Score:  3.075268817204301
Player 2 Score:  1.7849462365591398
#+END_SRC

The most obvious difference from =eye-for-eye= is that now the strategy lose
hugely against =spastic=; also the difference the scores each strategy would get
when it comes to with =nasty= got bigger than =eye-for-eye=. This is due to the
fact that now the strategy get harder to defect than previous, which results to
the bigger difference it get (this is bad thing since =eye-for-...= always loses
against other strategies).
** Problem 5
Write a procedure =make-eye-for-n-eyes=. This procedure should take a number as
input and return the appropriate =Eye-for-Eye=-like strategy. For example,
=(make-eye-for-n-eyes 2)= should returns a strategy equivalent to
=eye-for-two-eyes=. Use this procedure to create a new strategy and test it
against the other strategies. Describe the observed behavior.

Here is the code:
#+BEGIN_SRC scheme
(define (MAKE-EYE-FOR-n-EYE n)
  (lambda (my-history other-history)
    (define (has-history-less-than-n? n hist)
      (cond ((zero? n) false)
            ((empty-history? hist) true)
            (else
             (has-history-less-than-n? (-1+ n) (rest-of-plays hist)))))
    (define (defected-previous-n-rounds? n hist)
      (or (zero? n)
          (and (string=? (most-recent-play hist) "d")
               (defected-previous-n-rounds? (-1+ n) (rest-of-plays hist)))))
    (cond ((has-history-less-than-n? n my-history) "c")
          ((defected-previous-n-rounds? n other-history) "d")
          (else                           ;has "c" in previous n rounds
           "c"))))
#+END_SRC

And test:
#+BEGIN_SRC scheme
(play-loop nasty (make-eye-for-n-eye 5))

Player 1 Score:  1.2222222222222223
Player 2 Score:  .9444444444444444

(play-loop egalitarian (make-eye-for-n-eye 5))

Player 1 Score:  3.
Player 2 Score:  3.

(play-loop spastic (make-eye-for-n-eye 5))

Player 1 Score:  4.038834951456311
Player 2 Score:  1.4174757281553398

(play-loop eye-for-eye (make-eye-for-n-eye 5))

Player 1 Score:  3.
Player 2 Score:  3.
#+END_SRC

This general procedure inherit the property of =Eye-for-Eye= -- it always loses
against other strategies; it got worse -- the difference even got widen.
** Problem 6
Write a procedure =make-rotating-strategy= which takes as input two strategies
(say, =strat0= and =strat1=) and two integers (say =freq0= and =freq1=).
=make-rotating-strategy= should return a strategy which plays =strat0= for the
first =freq0= rounds in the iterated game, then switches to =strat1= for the
next =freq1= rounds, and so on. (Hint: you may find it useful to think about the
=remainder= procedure in order to decide which strategy to use at each
iteration.) Test it against other strategies and describe the performance.

Here is the code:
#+BEGIN_SRC scheme
(define (length-history hist)
  (if (empty-history? hist) 0
      (1+ (length-history (rest-of-plays hist)))))
(define (make-rotating-strategy strat0 strat1 freq0 freq1)
  (lambda (my-history other-history)
    (if (< (remainder (length-history my-history) (+ freq0 freq1))
           freq0)
        (strat0 my-history other-history)
        (strat1 my-history other-history))))
#+END_SRC

Tests:
#+BEGIN_SRC scheme
(play-loop (make-rotating-strategy nasty eye-for-eye 10 80) egalitarian)

Player 1 Score:  1.0396039603960396
Player 2 Score:  .9900990099009901

(play-loop (make-rotating-strategy nasty eye-for-eye 10 80) eye-for-eye)

Player 1 Score:  1.0396039603960396
Player 2 Score:  .9900990099009901

(play-loop (make-rotating-strategy nasty eye-for-eye 10 80) patsy)

Player 1 Score:  3.2795698924731185
Player 2 Score:  2.5806451612903225

(play-loop (make-rotating-strategy nasty eye-for-eye 10 80) nasty)

Player 1 Score:  1.
Player 2 Score:  1.

(play-loop (make-rotating-strategy nasty eye-for-eye 10 80) spastic)

Player 1 Score:  2.4361702127659575
Player 2 Score:  1.9042553191489362

(play-loop (make-rotating-strategy nasty eye-for-eye 10 80) spastic)

Player 1 Score:  2.297872340425532
Player 2 Score:  1.7127659574468086
#+END_SRC

We mixed =nasty= with =eye-for-eye= to complement each other: It becomes always
win the other one like the original =nasty= and I wished it to get good average
score as =eye-for-eye= does; but it turns out not.
** Problem 7
Write a new strategy, =make-higher-order-spastic=, which takes a list of
strategies as input. It returns a new strategy that loops through this list of
strategies, using the next one in the list for each play, and then starting
again at the beginning of the list when it has used all the strategies. Test
this new strategy against other strategies and describe the performance.

We use the same strategy with the previous problem:
#+BEGIN_SRC scheme
(define (make-higher-order-spastic strats)
  (lambda (my-history other-history)
    (let* ((index (remainder (length-history my-history) (length strats)))
           (strat (list-ref strats index)))
      (strat my-history other-history))))
#+END_SRC

Tests:
#+BEGIN_SRC scheme
(play-loop (make-higher-order-spastic (list eye-for-eye patsy nasty)) eye-for-eye)

Player 1 Score:  2.6989247311827955
Player 2 Score:  2.6451612903225805

(play-loop (make-higher-order-spastic (list eye-for-eye patsy nasty)) patsy)

Player 1 Score:  3.6530612244897958
Player 2 Score:  2.020408163265306

(play-loop (make-higher-order-spastic (list eye-for-eye patsy nasty)) egalitarian)

Player 1 Score:  3.6595744680851063
Player 2 Score:  2.0106382978723403

(play-loop (make-higher-order-spastic (list eye-for-eye patsy nasty)) spastic)

Player 1 Score:  2.31
Player 2 Score:  2.11

(play-loop (make-higher-order-spastic (list eye-for-eye patsy nasty)) spastic)

Player 1 Score:  2.0384615384615383
Player 2 Score:  2.2788461538461537

(play-loop (make-higher-order-spastic (list eye-for-eye patsy nasty)) nasty)

Player 1 Score:  .6568627450980392
Player 2 Score:  2.372549019607843
#+END_SRC
** Problem 8
Write a procedure =gentle=, which takes as input a strategy (say =strat=) and a
number between 0 and 1 (call it =gentleness-factor=). The =gentle= procedure
should return a strategy that plays the same as =strat= except: when =strat=
defects, the new strategy should have a =gentleness-factor= chance of
cooperating. (If =gentleness-factor= is 0, the return strategy performs exactly
the same as =strat=; if =gentleness-factor= is 0.5, the returned strategy
cooperates half the time that =strat= defects; if =gentleness-factor= is 1, the
returned strategy performs the same as =Patsy=.)

Use =gentle= with a low value for =gentleness-factor= -- say, 0.1 -- to create
two new strategies: =slightly-gentle-Nasty= and =slightly-gentle-Eye-for-Eye=.

Here is the code:
#+BEGIN_SRC scheme
(define (gentle strat gentleness-factor)
  (define (gentle-spastic)
    (if (< (random 1.0) gentleness-factor)
        "c"
        "d"))
  (lambda (my-history other-history)
    (let ((result (strat my-history other-history)))
      (if (string=? result "d")
          (gentle-spastic)
          result))))

(define slightly-gentle-Nasty
  (gentle nasty 0.1))

(define slightly-gentle-Eye-for-Eye
  (gentle eye-for-eye 0.1))
#+END_SRC

Here is the test:
#+BEGIN_SRC scheme
(play-loop nasty slightly-gentle-nasty)

Player 1 Score:  1.4210526315789473
Player 2 Score:  .8947368421052632

(play-loop eye-for-eye slightly-gentle-eye-for-eye)

Player 1 Score:  3.
Player 2 Score:  3.

(play-loop spastic slightly-gentle-eye-for-eye)

Player 1 Score:  2.4285714285714284
Player 2 Score:  2.020408163265306

(play-loop nasty slightly-gentle-eye-for-eye)

Player 1 Score:  1.2173913043478262
Player 2 Score:  .9456521739130435
#+END_SRC
** The Three-Player Prisoner's Dilemma
So far, all of our prisoner's dilemma examples have involved two players (and,
indeed, most game-theory research on the prisoner's dilemma has focused on
two-player games). But it is possible to create a prisoner's dilemma game
involve three -- or even more -- players.

Strategies from the two-player game do not necessarily extend to a three-person
game in a natural way. For example, what does =Eye-for-Eye= mean? Should the
player defect if /either/ of the opponents defected on the previous round? Or
only if /both/ opponents defected? And are either of these strategies nearly as
effective in the three-player game as =Eye-for-Eye= is in the two-player game?

Before we analyze the three-player game more closely, we must introduce some
notation for representing the payoffs. We use a notation similar to that used
for the two-player game. For example, we let $DCC$ represent the payoff to a
defecting player if both opponents cooperate. Note that the first position
represents the player under consideration. The second and third positions
represent the opponents.

Another example: $CCD$ represents the payoff to a cooperating player if one
opponent cooperates and the other opponent defects. Since we assume a symmetric
game matrix, $CCD$ could be written as $CDC$. The choice is arbitrary.

Now we are ready to discuss the payoffs for the three-player game. We impose
three rules (Actually, there is no universal definition for the multi-player
prisoner's dilemma. The constraints used here represent one possible version of
the three-player prisoner's dilemma.):

1. Defection should be the dominant choice for each player. In other words, it
   should always be better for a player to defect, regardless of what the
   opponents do. This rule gives three constraints:
   \begin{align*}
   DCC &> CCC\\
   DDD &> CDD\\
   DCD &> CCD
   \end{align*}
2. A player should always be better off if more of his opponents choose to
   cooperate. This rule gives:
   \begin{align*}
   DCC &> DCD > DDD\\
   CCC &> CCD > CDD\\
   \end{align*}
3. If one player's choice is fixed, the other two players should be left in a
   two-player prisoner's dilemma. This rule gives the following constraints:
   \begin{align*}
    CCD &> DDD\\
    CCC &> DCD\\
    CCD &> \frac{CDD + DCD}{2}\\
    CCC &> \frac{CCD + DCC}{2}
   \end{align*}
4. We can satisfy all of these constraints with the following payoffs:
   $$CDD = 0,\quad DDD = 1,\quad CCD = 2,\quad DCD = 3,\quad CCC = 4,\quad DCC =
   5.$$
** Problem 9
Revise the Scheme code for the two-player game to make a three-player iterated
game. The program should take three strategies as input, keep track of three
histories, and print out results for three players. We need to change only three
procedures: =play-loop=, =print-out-results= and =get-scores=.

We also need to change =*game-association-list*= as follows:
#+BEGIN_SRC scheme
(define *game-association-list*
  (list (list (list "c" "c" "c") (list 4 4 4))
        (list (list "c" "c" "d") (list 2 2 5))
        (list (list "c" "d" "c") (list 2 5 2))
        (list (list "d" "c" "c") (list 5 2 2))
        (list (list "c" "d" "d") (list 0 3 3))
        (list (list "d" "c" "d") (list 3 0 3))
        (list (list "d" "d" "c") (list 3 3 0))
        (list (list "d" "d" "d") (list 1 1 1))))
#+END_SRC

Here is the rest of code:
#+BEGIN_SRC scheme
(define (play-loop strat0 strat1 strat2)
  (define (play-loop-iter strat0 strat1 strat2 count history0 history1 history2 limit)
    (cond ((= count limit) (print-out-results history0 history1 history2 limit))
          (else (let ((result0 (strat0 history0 history1 history2))
                      (result1 (strat1 history1 history0 history2))
                      (result2 (strat2 history2 history0 history1)))
                  (play-loop-iter strat0 strat1 strat2 (+ count 1)
                                  (extend-history result0 history0)
                                  (extend-history result1 history1)
                                  (extend-history result2 history2)
                                  limit)))))
  (play-loop-iter strat0 strat1 strat2 0 the-empty-history the-empty-history the-empty-history
                  (+ 90 (random 21))))

(define (print-out-results history0 history1 history2 number-of-games)
  (let ((scores (get-scores history0 history1 history2)))
    (newline)
    (display "Player 1 Score:  ")
    (display (* 1.0 (/ (car scores) number-of-games)))
    (newline)
    (display "Player 2 Score:  ")
    (display (* 1.0 (/ (cadr scores) number-of-games)))
    (newline)
    (display "Player 3 Score:  ")
    (display (* 1.0 (/ (caddr scores) number-of-games)))
    (newline)
    ))

(define (get-scores history0 history1 history2)
  (define (get-scores-helper history0 history1 history2 score0 score1 score2)
    (cond ((empty-history? history0)
           (list score0 score1 score2))
          (else (let ((game (make-play (most-recent-play history0)
                                       (most-recent-play history1)
                                       (most-recent-play history2))))
                  (get-scores-helper (rest-of-plays history0)
                                     (rest-of-plays history1)
                                     (rest-of-plays history2)
                                     (+ (get-player-points 0 game) score0)
                                     (+ (get-player-points 1 game) score1)
                                     (+ (get-player-points 2 game) score2))))))
  (get-scores-helper history0 history1 history2 0 0 0))
#+END_SRC
** Problem 10
Write strategies =Patsy-3=, =Nasty-3=, and =spastic-3= that will work in a
three-player game. Try them out to make sure our code is working.

Write two new strategies: =tough-Eye-for-Eye= and =soft-Eye-for-Eye=.
=tough-Eye-for-Eye= should defect if /either/ of the opponents defected on the
previous round. =soft-Eye-for-Eye= should defect only if =both= opponents
defected on the previous round. Play some games using these two new strategies.
Describe the observed behavior of the strategies.

First task:
#+BEGIN_SRC scheme
(define (NASTY-3 my-history other-history another-history)
  "d")

(define (PATSY-3 my-history other-history another-history)
  "c")

(define (SPASTIC-3 my-history other-history another-history)
  (if (= (random 2) 0)
      "c"
      "d"))
#+END_SRC

And test:
#+BEGIN_SRC scheme
(play-loop nasty-3 patsy-3 spastic-3)

Player 1 Score:  4.08
Player 2 Score:  1.08
Player 3 Score:  2.46
#+END_SRC

Second task:
#+BEGIN_SRC scheme
(define (tough-EYE-FOR-EYE my-history other-history another-history)
  (cond ((empty-history? my-history) "c")
        ((or (string=? (most-recent-play other-history) "d")
             (string=? (most-recent-play another-history) "d"))
         "d")
        (else "c")))

(define (soft-EYE-FOR-EYE my-history other-history another-history)
  (cond ((empty-history? my-history) "c")
        ((and (string=? (most-recent-play other-history) "d")
              (string=? (most-recent-play another-history) "d"))
         "d")
        (else "c")))
#+END_SRC

And the behavior:
#+BEGIN_SRC scheme
(play-loop nasty-3 soft-eye-for-eye tough-eye-for-eye)

Player 1 Score:  1.0588235294117647
Player 2 Score:  1.
Player 3 Score:  1.0294117647058822

(play-loop patsy-3 soft-eye-for-eye tough-eye-for-eye)

Player 1 Score:  4.
Player 2 Score:  4.
Player 3 Score:  4.

(play-loop spastic-3 soft-eye-for-eye tough-eye-for-eye)

Player 1 Score:  2.4479166666666665
Player 2 Score:  1.9166666666666667
Player 3 Score:  3.0104166666666665

(play-loop spastic-3 soft-eye-for-eye tough-eye-for-eye)

Player 1 Score:  2.172727272727273
Player 2 Score:  1.7363636363636363
Player 3 Score:  2.690909090909091
#+END_SRC

=soft-Eye-for-Eye= inherit the characteristic property of =Eye-for-Eye= -- never
win against others; =tough-Eye-for-Eye= now tends to win with a slight
difference against others.
** Problem 11
Write a procedure =make-combined-strategies= which takes as input two
/two-player/ strategies and a "combining" procedure. =make-combined-strategies=
should return a /three-player/ strategy that plays one of the two-player
strategies against one of the opponents, and the other two-player strategy
against the other opponents, then calls the "combining" procedure on the two
two-player results. Here's an example: this call to =make-combined-strategies=
returns a strategy equivalent to =tough-Eye-for-Eye= in Problem 10.

The resulting strategy plays =Eye-for-Eye= against each opponent, and then calls
the combining procedure on the two results. If either of the two two-player
strategies has returned "d", then the three-player strategy will also return
"d".

#+BEGIN_SRC scheme
(make-combined-strategies
   Eye-for-Eye Eye-for-Eye
   (lambda (r1 r2) (if (or (string=? r1 "d") (string=? r2 "d")) "d" "c")))
#+END_SRC

Here's another example. This call to =make-combined-strategies= returns a
three-player strategy that plays =Eye-for-Eye= against one opponent,
=Egalitarian= against another, and choose randomly between the two results:
#+BEGIN_SRC scheme
(make-combined-strategies
   Eye-for-Eye Egalitarian
   (lambda (r1 r2) (if (= (random 2) 0) r1 r2)))
#+END_SRC

The code:
#+BEGIN_SRC scheme
;; (hist, hist -> action), (hist, hist -> action), (action, action -> action)
;; -> (hist, hist, hist -> action)
(define (make-combined-strategies two-strat0 two-strat1 combiner)
  (lambda (my-history other-history another-history)
    (combiner (two-strat0 my-history other-history)
              (two-strat1 my-hsitory another-history))))
#+END_SRC
We added the type notation of given procedure.

Then test:
#+BEGIN_SRC scheme
(define tough-eye-for-eye1
  (make-combined-strategies
   Eye-for-Eye Eye-for-Eye
   (lambda (r1 r2) (if (or (string=? r1 "d") (string=? r2 "d")) "d" "c"))))

(define randomized-egal-eye
  (make-combined-strategies
   Eye-for-Eye Egalitarian
   (lambda (r1 r2) (if (= (random 2) 0) r1 r2))))

(play-loop tough-eye-for-eye1 spastic-3 tough-eye-for-eye)

Player 1 Score:  2.0833333333333335
Player 2 Score:  .5
Player 3 Score:  2.0833333333333335

(play-loop tough-eye-for-eye1 soft-eye-for-eye tough-eye-for-eye)

Player 1 Score:  4.
Player 2 Score:  4.
Player 3 Score:  4.

(play-loop tough-eye-for-eye1 randomized-egal-eye tough-eye-for-eye)

Player 1 Score:  4.
Player 2 Score:  4.
Player 3 Score:  4.

(play-loop tough-eye-for-eye1 randomized-egal-eye spastic-3)

Player 1 Score:  2.988888888888889
Player 2 Score:  2.188888888888889
Player 3 Score:  2.5555555555555554
#+END_SRC
** Problem 12
A natural idea in creating a prisoner's dilemma strategy is to try and deduce
what kind of strategies the /other/ players might be using. In this problem, we
will implement a simple version of this idea.

The underlying idea is to keep track of how the strategy for one player
correlates with the decisions of the other two players on the previous round (or
course, you can imagine generalizing this to several previous rounds). Thus, we
want to build an intermediary data structure which keeps track of what player-0
did, correlated with what the other two players did, over the course of the
histories for the three players. Imagine creating a procedure that takes three
histories as arguments: call them =hist-0=, =hist-1= and =hist-2=. The idea is
that we wish to characterize the strategy of the player responsible for
=hist-0=. Given this is a three player game, there are three possible situations
we need to keep track of: What did player-0 do on one round when the two other
players both cooperated on the previous round; what did player-0 do on one round
when one of the others cooperated and the other defected on the previous round;
and what did player-0 do on one round when both other players defected on the
previous round. Since these three situations will occur multiple times, we want
to keep track of how often in each case did player-0 cooperate, and how often
did she defect in response to these choices, and how often did each of these
three cases occur (although that could be found by adding the number of times
player-0 cooperated and defected).

Thus, we should design and implement a data structure called a
=history-summary=, which the overall structure shown in Figure 1 (please
reference the relevant project document). The =history-summary= has three
sub-pieces, one for the case where both player-1 and player-2 cooperated, one
for when one of them cooperated and the other defected, and a third for when
both of these players defected. This means that our data abstraction for a
=history-summary= should have three selectors, for these three pieces. For each
piece, there is another data structure that keeps track of the number of times
player-0 cooperated on the next round, the number of times she defected, and the
total number of examples (though as we noted, this is redundant). We may find it
convenient to think of this as a kind of tree structure. Thus, our first task is
to design constructors and selectors to implement this multilevel abstraction.

Once we have designed our data abstraction, build a procedure that takes the
three histories as arguments, and returns a history-summary. If we extract from
this data structure the piece corresponding to =cooperate-cooperate=, this
should give us all the information about what happened when player-1 and player-2
both cooperated. Thus, we should be able to extract from this piece the number
of times player-0 cooperated and the number of times she defected.

REMEMBER: the goal of our data structure is to correlate player-0's behavior on
round n, with player-1 and player-2's behavior on round n-1. For example, the
result of an implementation, call it =make-history-summary=, on an example set
of histories is shown below:
#+BEGIN_SRC scheme
(define summary
  (make-history-summary
   '("c" "c" "d" "d" "c" "d" "c" "c")   ;hist-0
   '("c" "c" "c" "d" "d" "c" "d" "c")   ;hist-1
   '("c" "c" "d" "d" "d" "c" "c" "c"))) ;hist-2

summary
;Value: ((3 0 3) (1 1 2) (0 2 2))
#+END_SRC

We implemented above specification as iterative process:
#+BEGIN_SRC scheme
;; constructor
;; (hist,hist,hist) -> history-summary
(define (make-history-summary hist-0 hist-1 hist-2)
  (define (raise-exception)
    (error "Invalid input histories -- MAKE-HISTORY-SUMMARY"
           (list hist-0 hist-1 hist-2)))
  (define (helper h0 prev-other-hist prev-another-hist sub-branches)
    (let ((current-action (most-recent-play h0)))
      (cond ((and (empty-history? prev-other-hist) ;termination condition
                  (empty-history? prev-another-hist))
             sub-branches)
            ((or (empty-history? prev-other-hist) ;defensive programming
                 (empty-history? prev-another-hist))
             (raise-exception))
            (else                       ;transition step
             (let ((prev-other-action (most-recent-play prev-other-hist))
                   (prev-another-action (most-recent-play prev-another-hist))
                   (cc (car sub-branches)) ;cooperate-cooperate
                   (cd (cadr sub-branches)) ;cooperate-defect
                   (dd (caddr sub-branches))) ;defect-defect
               (helper
                (rest-of-plays h0)
                (rest-of-plays prev-other-hist)
                (rest-of-plays prev-another-hist)
                (cond ((and (string=? prev-other-action "c")
                            (string=? prev-another-action "c")) ;update cc
                       (list (cond ((string=? current-action "c")
                                    (increase-c-action cc)) ;update c
                                   ((string=? current-action "d")
                                    (increase-d-action cc)) ;update d
                                   (else (raise-exception)))
                             cd
                             dd))
                      ((and (string=? prev-other-action "d")
                            (string=? prev-another-action "d")) ;update dd
                       (list cc
                             cd
                             (cond ((string=? current-action "c")
                                    (increase-c-action dd))
                                   ((string=? current-action "d")
                                    (increase-d-action dd))
                                   (else (raise-exception)))))
                      ((or (and (string=? prev-other-action "d") ;update cd
                                (string=? prev-another-action "c"))
                           (and (string=? prev-other-action "c")
                                (string=? prev-another-action "d")))
                       (list cc
                             (cond ((string=? current-action "c")
                                    (increase-c-action cd))
                                   ((string=? current-action "d")
                                    (increase-d-action cd))
                                   (else (raise-exception)))
                             dd))
                      (else
                       (raise-exception))))))))) ;defensive programming
  (let ((cc (make-action-history 0 0 0))
        (cd (make-action-history 0 0 0))
        (dd (make-action-history 0 0 0)))
      (cond ((and (empty-history? hist-0) ;trivial condition
                  (empty-history? hist-1)
                  (empty-history? hist-2))
             (list cc cd dd))
            ((or (empty-history? hist-0) ;defensive programming
                 (empty-history? hist-1)
                 (empty-history? hist-2))
             (raise-exception))
            (else                       ;nontrivial case
             (helper hist-0             ;setup initial condition
                     (rest-of-plays hist-1)
                     (rest-of-plays hist-2)
                     (list cc cd dd)))))
  )

;; selector
(define (cooperate-cooperate history-summary)
  (car history-summary))
(define (cooperate-defect history-summary)
  (cadr history-summary))
(define (defect-defect history-summary)
  (caddr history-summary))

;; test for make-history-summary
;; (define summary
;;   (make-history-summary
;;    '("c" "c" "d" "d" "c" "d" "c" "c")   ;hist-0
;;    '("c" "c" "c" "d" "d" "c" "d" "c")   ;hist-1
;;    '("c" "c" "d" "d" "d" "c" "c" "c"))) ;hist-2

;; summary
;; ;Value: ((3 0 3) (1 1 2) (0 2 2))

;; operate on action-history
;; action-history -> action-history
(define (increase-c-action action-history)
  (make-action-history
   (1+ (c-action action-history))
   (d-action action-history)
   (1+ (t-action action-history))))
(define (increase-d-action action-history)
  (make-action-history
   (c-action action-history)
   (1+ (d-action action-history))
   (1+ (t-action action-history))))

;; lowest ADT for history-summary type
;; integer, integer, integer -> action-history
(define (make-action-history cooperations defections total-actions)
  (list cooperations defections total-actions))
;; (c-action (make-action-history <cs> <ds> <as>)) = <cs>
(define (c-action action-history)
  (car action-history))
;; (d-action (make-action-history <cs> <ds> <as>)) = <ds>
(define (d-action action-history)
  (cadr action-history))
;; (t-action (make-action-history <cs> <ds> <as>)) = <as>
(define (t-action action-history)
  (caddr action-history))
#+END_SRC

Then as usual we test our procedure:
#+BEGIN_SRC scheme
(define summary
  (make-history-summary
   '("c" "c" "d" "d" "c" "d" "c" "c")   ;hist-0
   '("c" "c" "c" "d" "d" "c" "d" "c")   ;hist-1
   '("c" "c" "d" "d" "d" "c" "c" "c")))

;Value: summary

summary

;Value: ((3 0 3) (1 1 2) (0 2 2))

(cooperate-defect summary)

;Value: (1 1 2)

(defect-defect summary)

;Value: (0 2 2)

(cooperate-cooperate summary)

;Value: (3 0 3)
#+END_SRC

The algorithm behind this implementation is straightforward:
1. Check the inputs are trivial case.
2. If it is do the right thing; if not set up the initial condition for the
   iterative process. You may find it helpful to draw table to catch up this process.
3. Depending on the current looks update appropriately then iterate over (transition).
4. If we encountered with termination condition then return the list of action-histories.


In the above description, we omitted the gory details about the defensive programming
and implementation details.
** Problem 13
Finally, using this data structure, we can build a new procedure that will
return a list of three numbers: the probability that the =hist-0= player
cooperates given that the other two players cooperated on the previous round,
the probability that the =hist-0= player cooperates given that only one other
player cooperated on the previous round, and the probability that the =hist-0=
player cooperates given that both others defected on the previous round. To fill
out some details in this picture, let's look at a couple of examples. We will
call our procedure =get-probability-of-c=: here are a couple of sample calls.
#+BEGIN_SRC scheme
(define summary (make-history-summary
                 '("c" "c" "c" "c")     ;hist-0
                 '("d" "d" "d" "c")     ;hist-1
                 '("d" "d" "c" "c")))   ;hist-2
(get-probability-of-c summary)
;; Value: (1 1 1)

(define new-summary (make-history-summary
                     '("c" "c" "c" "d" "c")
                     '("d" "c" "d" "d" "c")
                     '("d" "c" "c" "c" "c")))
(get-probability-of-c new-summary)
;; Value: (0.5 1 ())
#+END_SRC

In the top example, the returned list indicates that the first player cooperates
with probability 1 no matter what the other two players do. In the bottom
example, the first player cooperates with probability 0.5 when the other two
players cooperate; the first player cooperates with probability 1 when one of
the other two players defects; and since we have no data regarding what happens
when both of the other players defect, our procedure returns =()= for that case.

Then here is the result:
#+BEGIN_SRC scheme
;; history-summary -> List<number>
(define (get-probability-of-c history-summary)
  (define (get-prob action-history)
    (if (zero? (t-action action-history))
        '()
        (* 1.0 (/ (c-action action-history)
                  (t-action action-history)))))
  (list (get-prob (cooperate-cooperate history-summary))
        (get-prob (cooperate-defect history-summary))
        (get-prob (defect-defect history-summary))))
#+END_SRC

Test:
#+BEGIN_SRC scheme
(define summary (make-history-summary
                 '("c" "c" "c" "c")     ;hist-0
                 '("d" "d" "d" "c")     ;hist-1
                 '("d" "d" "c" "c")))

;Value: summary

(get-probability-of-c summary)

;Value: (1. 1. 1.)

(define new-summary (make-history-summary
                     '("c" "c" "c" "d" "c")
                     '("d" "c" "d" "d" "c")
                     '("d" "c" "c" "c" "c")))

;Value: new-summary

(get-probability-of-c new-summary)

;Value: (.5 1. ())
#+END_SRC
** Problem 14
Using this procedure, you should be able to write some predicate procedures that
help in deciphering another player's strategy. For instance, we can use
=get-probability-of-c= to record the behavior of an opponent. We could then
compare this against what we would expect for a behavior to see if they match.
Thus, the first procedure tests to see if two lists are the same. Using this we
could check to see if an opponent is a fool by seeing if he always cooperates
(i.e. the observed behavior would be a "c" for cooperate in all cases).

#+BEGIN_SRC scheme
(define (test-entry expected-values actual-values)
  (cond ((null? expected-values) (null? actual-values))
        ((null? actual-values) #f)
        ((or (not (car expected-values))
             (not (car actual-values))
             (= (car expected-values) (car actual-values)))
         (test-entry (cdr expected-values) (cdr actual-values)))
        (else #f)))

(define (is-he-a-fool? hist0 hist1 hist2)
  (test-entry (list 1 1 1)
              (get-probability-of-c
               (make-history-summary hist0 hist1 hist2))))

(define (could-he-be-a-fool? hist0 hist1 hist2)
  (test-entry (list 1 1 1)
              (map (lambda (elt)
                     (cond ((null? elt) 1)
                           ((= elt 1) 1)
                           (else 0)))
                   (get-probability-of-c (make-history-summary hist0
                                                               hist1
                                                               hist2)))))
#+END_SRC

Use the =get-probability-of-c= procedure to write a predicate that tests whether
another player is using the =soft-Eye-for-Eye= strategy from Problem 10. Also,
write a new strategy named =dont-tolerate-fools=. This strategy should cooperate
for the first ten rounds; on subsequent rounds it checks (one each round) to see
whether the other players might both be playing =Patsy=. If our strategy finds
that both other players seem to be cooperating uniformly, it defects; otherwise,
it cooperate.

To make testing our implementation easier, let we amend the =play-loop=
procedure to return played histories:
#+BEGIN_SRC scheme
(define (play-loop strat0 strat1 strat2)
  (define (play-loop-iter strat0 strat1 strat2 count history0 history1 history2 limit)
    (cond ((= count limit)
           (print-out-results history0 history1 history2 limit)
           (list history0 history1 history2)) ;for testing
          (else (let ((result0 (strat0 history0 history1 history2))
                      (result1 (strat1 history1 history0 history2))
                      (result2 (strat2 history2 history0 history1)))
                  (play-loop-iter strat0 strat1 strat2 (+ count 1)
                                  (extend-history result0 history0)
                                  (extend-history result1 history1)
                                  (extend-history result2 history2)
                                  limit)))))
  (play-loop-iter strat0 strat1 strat2 0 the-empty-history the-empty-history the-empty-history
                  (+ 90 (random 21))))
#+END_SRC

Then our first task:
#+BEGIN_SRC scheme
(define (is-he-soft-eye-for-eye? hist0 hist1 hist2)
  (test-entry (list 1 1 0)
              (get-probability-of-c
               (make-history-summary hist0 hist1 hist2))))
#+END_SRC
with the test:
#+BEGIN_SRC scheme
(let ((result-histories (play-loop soft-eye-for-eye spastic-3 tough-eye-for-eye1)))
  (is-he-soft-eye-for-eye? (car result-histories)
                           (cadr result-histories)
                           (caddr result-histories)))

Player 1 Score:  2.2058823529411766
Player 2 Score:  2.823529411764706
Player 3 Score:  3.176470588235294
;Value: #t
#+END_SRC

And our last task:
#+BEGIN_SRC scheme
;; hist, hist, hist -> action
(define (dont-tolerate-fools my-history other-history another-history)
  (cond ((<= (length-history my-history) 10) "c")
        ((and (could-he-be-a-fool? other-history my-history another-history)
              (could-he-be-a-fool? another-history my-history other-history))
         "d")
        (else "c")))
#+END_SRC

Here we used =could-he-be-a-fool?= instead of =is-he-a-fool?= since there is no
assurance that all the argument histories possess ="d"= as action.

The resulting test comes as:
#+BEGIN_SRC scheme
(play-loop dont-tolerate-fools patsy-3 patsy-3)

Player 1 Score:  4.897196261682243
Player 2 Score:  2.205607476635514
Player 3 Score:  2.205607476635514

(play-loop dont-tolerate-fools spastic-3 patsy-3)

Player 1 Score:  3.1868131868131866
Player 2 Score:  4.406593406593407
Player 3 Score:  3.1868131868131866
#+END_SRC

If we inspect the resulting histories from =play-loop=, we can convince ourself
that our implementation is highly likely correct.
* Project 3 -- Crawling adn Indexing the World Wide Web
This project explores some issues that arise in constructing a "spider" or a
"web agent" that crawls over documents in the World Wide Web. For purposes of
this project, the Web is an extremely large collection of documents. Each
document contains some text and also links to other documents, in the form of
URLs.

In this project, we'll be working with programs that can start with an initial
document and follow the reference to other documents to do useful things. For
example, we could construct an index of all the words occurring in documents,
and make this available to people looking for information on the web (as do many
of the search engines on the web, such as Google or Yahoo).

Usually, we aren't fluent with the details of HTTP, URLs, URIs, HTML, XML, XSL,
HTTP-NG, DOM, and the rest of the alphabet soup that makes up the technical
details of the Web, here's a simplified version of what goes on behind the
scenes:

1. The Web consists of a very large number of things called documents,
   identified by names called URLs (Uniform Resource Locators). For example, the
   6.001 home page has the URL http://sicp.csail.mit.edu/. The first portion of
   a URL (~http://~) reveals the name of a protocol (in this case hypertext
   transmission protocol, or HTTP) that can be used to fetch the document, and
   the rest of the URL contains information needed by the protocol to specify
   which document is intended. (A protocol is a particular set of rules for how
   to communicate information.)
2. By using the HTTP protocol, a program (most commonly a browser but any
   program can do this -- "web agents" and spiders are examples of such programs
   that aren't browsers)[fn:1] can retrieve a document whose URL starts with
   ~HTTP:~. The document is returned to the program, along with information
   about how it is encoded, for example, ASCII or Unicode text, HTML, images in
   GIF or JPG or MPEG or PNG or some other format, an Excel or Lotus
   spreadsheet, etc.
3. Documents encoded in HTML (HyperText Markup Language) form can contain a
   mixture of text, images, formatting information, and links to other
   documents. Thus, when a browser (or other program) gets an HTML document, it
   can extract the links from it, yielding URLs for other documents in the Web.
   If these are in HTML format, then they too can be retrieved and will yield
   yet more links, and so on.
4. A /spider/ is a program that starts with an initial set of URLs, retrieves
   the corresponding documents, adds the links from these documents to the set
   of URLs and keeps on going. Every time it retrieves a document, it does some
   (hopefully useful) work in addition to just finding the embedded links.
5. One particularly interesting kind of spider constructs an /index/ of the
   documents it has seen. This index is similar to the index at the end of a
   book: it has certain key words and phrases, and for each entry it lists all
   of the URLs that contain that word or phrase. There are many kinds of
   indexes, and the art/science of deciding what words or phrases to index and
   how to extract them is at the cutting edge of research (it's part of the
   discipline called /information retrieval/). We'll talk mostly about /full
   text indexing/, which means that every word in the document (except, perhaps,
   the very common words like "and", "the," "a," and "an") is indexed.


In this project, we'll be interested in three tasks related to searching the
World Wide Web. First, we will develop a way to think about the "web" of links
as a directed graph. Second, we will build procedures to help in traversing or
searching through graphs such as the Web. Third, we will consider ways to build
an index for some set of web pages to support fast retrieval of URLs that
contain a given word.

** Directed Graphs
The essence of the Web, for the purpose of understanding the process of
searching, is captured by a formal abstraction called a /directed graph/. A
graph (like the one in Figure 1), consists of
/nodes/ and /edges/. In this figure, the nodes are labeled U through Z. Nods are
connected to other nodes via /edges/. In a directed graph, each edge has a
direction so that the existence of an /outgoing edgy/ from one node to another
node (e.g. from node Y to node X). Notice that there can be multiple outgoing
edges from a node as well as multiple /incoming/ edges to a node, e.g. there are
edges from both Y and Z to W. The set of nodes reachable via a single outgoing
edge from a given node is referred to as the node's /children/. For example, the
children of node W are nodes U and X. Lastly, a graph is said to contain a cycle
if you start from some node and manage to return to that same node after
traversing one or more edges. So for example, the nodes W, X and Y form a cycle,
as does the node V by itself.

#+BEGIN_SRC dot :file ../image/fig1.png 
digraph {
X -> { V Y };
V -> V;
Y -> { Z W };
W -> X;
Z -> W;
W -> U;
U -> W;
}
#+END_SRC

#+caption: Figure 1: An example of a general graph.
#+RESULTS:
[[file:../image/fig1.png]]

A second example of a directed graph is shown in Figure 2. This particular
directed graph happens to be a tree: each node is pointed to by only one other
node and thus there is no sharing of nodes, and there are no cycles (or loops).

#+BEGIN_SRC dot :file ../image/fig2.png
digraph {
A -> { B I M };
B -> { C D E H };
E -> { F G };
I -> { J K L };
}
#+END_SRC

#+caption: Figure 2: An example of a tree, viewed as a directed graph.
#+RESULTS:
[[file:../image/fig2.png]]

In order to traverse a directed graph, let's assume that we have two selectors
for getting information from the graph:
- =(find-node-children <graph> <node>)= returns a list of the nodes in =<graph>=
  that can be reached in one step by outbound edges from =<node>=. For example,
  in Figure 2 the children of node B are C, D, E, and H -- things that can be
  reached in one hop by an outgoing edge.
- =(find-node-contents <graph> <node>)= returns the contents of the node. For
  example, when we represent the web as a graph, we will want the node contents
  to be an alphabetized list of all of the words occuring in the document at /node/.


Note, we have not said anything yet about the actual representation of a graph,
a node, or an edge. We are simply stating an abstract definition of a data
structure.

*** The Web as a Graph
The Web itself can be thought as a directed graph in which the nodes are HTML
documents and the edges are hyperlinks to other HTML documents. For example, in
Figure 2 the node labeled B would be a URL, and a directed edge exists between
two nodes B and E if the document represented by node B contains a link to the
document represented by node E (as it does in this case).

As mentioned earlier, a web spider (or web crawler) is a program that traverses
the web. A web spider might support procedures such as:
- =(find-URL-links <web> <URL>)= returns a list of the URLs that are outbound links
  from /URL/.
- =(find-URL-text <web> <URL>)= returns an alphabetized list of all the words
  occurring in the document at /URL/.


Note, we have not said anything yet about the actual representation of the web
as we did in graph: we are simply stating an abstract definition of a data
structure.

In a real web crawler, =find-URL-links= would involve retrieving the document
over the network using its URL, parsing the HTML information returned by the web
server, and extracting the link information from ~<a href=...>~, ~<image
src=...>~ and similar tags. Similarly, in a real web crawler, =<find-URL-text
<web> <URL>= would retrieve the document, discard all of the mark-up commands
(such as =<body>=, =<html>=, =<ul>=, etc.), alphabetize (and remove duplicates
from) the text, and return the resulting list of words.

For this project our programs will not actually go out the retrieve documents
over the web. Instead, we will represent a collection of web documents as a
/graph/ as discussed earlier. When we load the code for this project, we will
have available a global variable, =the-web=, which holds the graph
representation for a set of documents for use in this project.

*Note:* it is important to separate our particular representation of information
on the web from the idea of the web as a loose collection of documents. We are
choosing to use a graph to capture a simple version of the web -- this is simply
to provide us with a concrete representation of the web, so that we can examine
issues related to exploring the web. In practice, we would never build an entire
representation of the web, we would simply take advantage of the abstraction to
conceptualize the structure of the web, especially since it is a dynamic thing
that constantly changes.

Our implementation of =find-URL-links= and =find-URL-text= will simply use the
graph procedures to get web links (children) and web page contents:

#+BEGIN_SRC scheme
(define (find-URL-links web url)
  (find-node-children web url))

(define (find-URL-text web url)
  (find-node-contents web url))
#+END_SRC

In other words, we are converting operations that would normally apply to the
web itself into operations that work on the internal representation of the web
as a graph.
*** Directed Graph Abstraction
We will build a graph abstraction to capture the relationships as shown in
Figure 1 and 2, as well as enable us to have some contents at each node. We
should study the code in =search.scm= provided with the project very closely;
parts of it are described in the following discussion.

We will assume that our graph is represented as a collection of graph-elements.
Each graph-element will itself consist of a node (represented as a symbol -- the
name of the node), a list of children nodes, and some contents stored at the
node (which in general can be of any type). The constructors, type predicate,
and accessors for the =graph-element= abstraction are shown below:
#+BEGIN_SRC scheme
;;; Graph Abstraction
;;;
;;;   Graph                     a collection of Graph-Elements
;;;   Graph-Element               a node, outgoing children from the
;;;                               node, and contents for the node
;;;   Node = symbol             a symbol label or name for the node
;;;   Contents = anytype        the contents for the node

;;---------------
;; Graph-Element

; make-graph-element: Node,list<Node>,Contents -> Element
(define (make-graph-element node children contents)
  (list 'graph-element node children contents))

(define (graph-element? element)            ; anytype -> boolean
  (and (pair? element) (eq? 'graph-element (car element))))

; Get the node (the name) from the Graph-Element
(define (graph-element->node element)       ; Graph-Element -> Node
  (if (not (graph-element? element))
      (error "object not element: " element)
      (first (cdr element))))

; Get the children (a list of outgoing node names)
; from the Graph-Element
(define (graph-element->children element)   ; Graph-Element -> list<Node>
  (if (not (graph-element? element))
      (error "object not element: " element)
      (second (cdr element))))

; Get the contents from the Graph-Element
(define (graph-element->contents element)   ; Graph-Element -> Contents
  (if (not (graph-element? element))
      (error "object not element: " element)
      (third (cdr element))))
#+END_SRC

Given this representation for a graph-element, we can build the graph out of
these elements as follows:
#+BEGIN_SRC scheme
(define (make-graph elements)            ; list<Element> -> Graph
  (cons 'graph elements))

(define (graph? graph)                  ; anytype -> boolean
  (and (pair? graph) (eq? 'graph (car graph))))

(define (graph-elements graph)           ; Graph -> list<Graph-Element>
  (if (not (graph? graph))
      (error "object not a graph: " graph)
      (cdr graph)))

(define (graph-root graph)		; Graph -> Node|null
  (let ((elements (graph-elements graph)))
    (if (null? elements)
        '()
        (graph-element->node (car elements)))))
#+END_SRC

In the above implementation, we will arbitrarily consider the first
graph-element to hold the "root" for the graph. The procedure =graph-root=
returns the root node.

Given these abstractions, we can construct the graph in Figure 2 (with node =a=
as the root) using:
#+BEGIN_SRC scheme
(define test-graph
  (make-graph (list
   (make-graph-element 'a '(b i m) '(some words))
   (make-graph-element 'b '(c d e h) '(more words))
   (make-graph-element 'c '() '(at c node some words))
   (make-graph-element 'd '() '())
   (make-graph-element 'e '(f g) '(and even more words))
   (make-graph-element 'f '() '())
   (make-graph-element 'g '() '())
   (make-graph-element 'h '() '())
   (make-graph-element 'i '(j k l) '(more words yet))
   (make-graph-element 'j '() '())
   (make-graph-element 'k '() '())
   (make-graph-element 'l '() '()))))
#+END_SRC

Note that several of the nodes have no children, and that several have no
contents.

We would like to have some accessors to get connectivity and contents
information out of the graph. We first define a procedure to find a
graph-element in a graph, given the node (i.e. the symbol or name that
identifies the element):

#+BEGIN_SRC scheme
; Find the specified node in the graph
(define (find-graph-element graph node)   ; Graph,Node -> Graph-Element|null
  (define (find elements)
    (cond ((null? elements) '())
          ((eq? (graph-element->node (car elements)) node)
           (car elements))
          (else (find (cdr elements)))))
  (find (graph-elements graph)))
#+END_SRC

We are often more interested in the node children or node contents, rather than
the graph-element. The =find-node-children= and =find-node-contents= accessor
procedure can be implemented as follows:

#+BEGIN_SRC scheme
; Find the children of the specified node in the graph
(define (find-node-children graph node)        ; Graph,Node -> list<Node>|null
  (let ((element (find-graph-element graph node)))
    (if (not (null? element))
        (graph-element->children element)
        '())))

; Find the contents of the specified node in the graph
(define (find-node-contents graph node)         ; Graph,Node -> Contents|null
  (let ((element (find-graph-element graph node)))
    (if (not (null? element))
        (graph-element->contents element)
        '())))
#+END_SRC

In our representation above, we use node names (~Node = symbol~) to reference a
=graph-element= in a =graph=; the children of a node are represented as a list
of other node names. An alternative to this approach would be to make the node
itself a full abstract data type, so that a node /object/ would have identity,
and the children of a node could be, for example, a list of the actual children
node objects. The tradeoff would be more work in building the graph (e.g. to
link together actual node objects as nodes and edges are added to a
graph[fn:2]), but substantial savings when nodes are requested from the graph
(i.e. by avoiding a linear search of the graph-elements for the matching node
name) -- e.g. to extract the node's contents or children. With such an
alternative abstraction, when requesting a child node one can achieve constant
time access (in the size of the graph), as opposed to linear time access as in
the current implementation[fn:3].
** Searching a Graph
How can we search a graph? The basic idea is that we need to start at some node
and traverse the graph in some fashion looking for some goal. The search might
succeed (meaning that some goal is found), or it might fail (meaning that some
goal was not found). This very basic and abstract search behavior can be
captured in the following procedure:

#+BEGIN_SRC scheme
;; search: Node, (Node->Boolean), (Graph, Node -> List<Node>)
;;         (List<Node>, List<Node> -> List<Node>), Graph
;;           --> Boolean

(define (search initial-state goal? successors merge graph)
  ;; initial-state is the start state of the search
  ;;
  ;; goal? is the predicate that determines whether we have
  ;; reached the goal
  ;;
  ;; successors computes from the current state all successor states
  ;;
  ;; merge combines new states with the set of states still to explore
  (define (search-inner still-to-do)
    (if (null? still-to-do)
        #f
        (let ((current (car still-to-do)))
          (if *search-debug*
              (write-line (list 'now-at current)))
          (if (goal? current)
              #t
              (search-inner
               (merge (successors graph current) (cdr still-to-do)))))))
  (search-inner (list initial-state)))
#+END_SRC

Note the use of the =*search-debug*= flag. If we set this global variable to
=#t=, we will see the order in which the procedure is traversing the graph.

*** Looking at search
What does this search procedure do? Well, let's look at it a bit more closely.
=Search= takes several arguments. The first is the initial state of the search.
For our purposes, this will be a =Node= or in other words, the name of some node
in our graph. The second is a =goal?= procedure, which is applied to a node to
determine if we have reached our goal. This procedure will presumably examine
some aspect of the node (for example, maybe it wants to see if a particular word
is contained in the contents of that node) to decide if the search has reached
its termination point. The third is a procedure for finding the =successors= of
the node, which in this case basically means finding the children of a node in
the graph on which we are searching. The fourth is a procedure for combining the
children of a node with any other nodes that we still have to search. And the
final argument is the graph over which we are searching.

Looking at the code, you can see that we start with a list of nodes to search.
If the first one meets our =goal?= criterion, we stop. If not, we get the
children of the current node, and combine them in some fashion with the other
nodes in our collection to search. This then becomes our new list of nodes to
consider, and we continue.
*** Search Strategies
There are two common approaches for searching directed graphs, called
/depth-first search/ and /breath-first search/. In a depth-first search we start
at a node, pick one of the outgoing links from it, explore that link (and all of
that link's outgoing links, and so on) before returning to explore the next link
out of our original node. For the graph in Figure 2, that would mean we would
examine the nodes (if we go left-to-right as well as depth-first) in the order:
/a, b, c, d, e, g, h, i, j, k, l,/ and finally /m/ (unless we found our goal
earlier, of course). The name "depth-first" comes from the fact that we go down
the graph (in the above drawing) before we go across.

In a breadth-first search, we visit a node and then all of its "siblings" first,
before exploring any "children." For Figure 2, we'd visit the nodes in the order
/a, b, i, m, c, d, e, h, j, k, l, f, g/.

We can abstract the notions of depth-first, breadth-first, and other kinds of
searches using the idea of a /search strategy/. A search strategy will basically
come down to what choice we make for how to order the nodes to be explored.
*** A Depth-First Strategy
Here's an initial attempt at a depth-first search strategy. It doesn't quite
work on all cases, but it's a good place to start.

#+BEGIN_SRC scheme
(define (DFS-simple start goal? graph)
  (search start
          goal?
          find-node-children
          (lambda (new old) (append new old))
          graph))
#+END_SRC

And here is an example of using it:

#+BEGIN_SRC scheme
(DFS-simple 'a
            (lambda (node) (eq? node 'l))
            test-graph)
#+END_SRC

In this case, we are searching a particular graph =test-graph=, starting from a
node with name =a=. We are looking for a node named =l= (hence our second
argument). We use our graph abstraction to extract the children of a node (i.e.
=find-node-children=). The key element is how we choose to order the set of
nodes to be explored. Note the fourth argument. We can see that this will
basically take the list of nodes to be explored, and add the new children in
front of the list. This should give us a depth first search (you should think
carefully about why).

This simple method does not work in general, but it does work for the graph in
Figure 2. (See Warm Up Exercise 2 for some thoughts on why this algorithm does
not work on all graphs.[fn:4])
** An Index Abstraction
We will also be interested in constructing an index of web pages. To do this, we
will first construct a general purpose index abstraction, and then use it for
our purpose of web indexing.

An =Index= enables us to associate values with keys, and to retrieve those
values later on given the key. Here we will assume that a key is a Scheme
symbol (i.e. ~Key = symbol~), and that a value is also a symbol (i.e. ~Val =
symbol~). Our index will be a mutable data structure.

A concrete implementation for an =index= is as follows. An =Index= will be a
tagged data object that holds a list of =INdex-Entries=. Each =Index-Entry=
associates a =Key= with a list of values for that =Key=, i.e.
#+BEGIN_SRC scheme
;;   Index = Pair<Index-Tag, list<Index-Entry>>
;;   Index-Entry = list<Key, list<Val>>
#+END_SRC

Thus our index implementation is shown (partially) below. We will be asked in
the exercises to complete the implementation. The index implementation makes use
of the Scheme procedure =assv=; you will find it helpful to consult the [[https://www.gnu.org/software/mit-scheme/documentation/mit-scheme-ref/Association-Lists.html][Scheme
manual]] as to what this procedure does.

#+BEGIN_SRC scheme
(define (make-index)            ; void -> Index
  (list 'index))

(define (index? index)          ; antype -> boolean
  (and (pair? index) (eq? 'index (car index))))

                                        ; This is an internal helper procedure not to
                                        ; be used externally.
(define (find-entry-in-index index key)
  (if (not (index? index))
      (error "object not an index: " index)
      (let ((entry (assv key (cdr index))))
        (if entry entry '()))))


                                        ; returns a list of values associated with key
(define (find-in-index index key)       ; Index,Key -> list<Val>
  (let ((index-entry (find-entry-in-index index key)))
    (if (not (null? index-entry))
        (cadr index-entry)
        '())))

;; TO BE IMPLEMENTED
(define (add-to-index! index key value) ; Index,Key,Val -> Index
  (let ((index-entry (find-entry-in-index index key)))
    (if (null? index-entry)
        ;; no entry -- create and insert a new one...
                                        ;... TO BE IMPLEMENTED

        ;; entry exists -- insert value if not already there...
                                        ;... TO BE IMPLEMENTED
        ))
  index)
#+END_SRC

An example use of the index is shown below
#+BEGIN_SRC scheme
(define test-index (make-index))
(add-to-index! test-index 'key1 'value1)
(add-to-index! test-index 'key2 'value2)
(add-to-index! test-index 'key1 'another-value1)

(find-in-index test-index 'key1)
;Value: (another-value1 value1)
(find-in-index test-index 'key2)
;Value: (value2)
#+END_SRC
** Warmup Exercises
These exercises will get we thinking about the project. We suggested to do them
early. Doing these stuffs will help us to understand aspects of the project.

*** Warmup Exercise 1: Index Implementation.
In order to simply /use/ the index abstraction, one should not need to
understand the underlying implementation (both the structure of the data
representation and the implementation of the abstract procedures). In one of the
programming exercises, however, you will be asked to complete the implementation
of =add-to-index!= partially shown above. In order to do this, we /will/ need to
understand the index implementation.

Draw a box and pointer diagram, and show the corresponding printed
representation, to illustrate the implementation of an =Index= as defined in
Section 3. Think about how you want the following expressions to create and then
mutate your data structure:

#+BEGIN_SRC scheme
(define test-index (make-index))
(add-to-index! test-index 'key1 'value1)
(add-to-index! test-index 'key2 'value2)
(add-to-index! test-index 'key1 'another-value1)
#+END_SRC

I've done this using the Digital Paper. You should find yourself comfortable to
draw box and pointer diagram with mutation beforehand.
*** Warmup Exercise 2: The Web as General Graph
Although we've been presenting the concepts and ideas in this problem set in the
context of the Web, for the project you will be ysing data structures that have
been pre-bulit. Thus, we will not be interfacing or touching the Web directly;
instead, we will be dealing with a graph data structure they've created for us
called =the-web=.

The following partial definition of =the-web= mimics a subset of the graph of
web pages at the 6.001 web site. Each node here is the URL of a web page and the
children nodes are the URLs referenced in the links on the page.

#+BEGIN_SRC scheme
(define the-web
  (list
   (make-graph-element
    'http://sicp.csail.mit.edu/
    '(http://sicp.csail.mit.edu/SchemeImplementations/
      http://sicp.csail.mit.edu/projects/)
    '(... words extracted from http://sicp.csail.mit.edu/ ...))
   (make-graph-element
    'http://sicp.csail.mit.edu/projects/
    '(http://sicp.csail.mit.edu/collaborative-work.html
      http://sicp.csail.mit.edu/getting-help.html)
    '(... words extracted from http://sicp.csail.mit.edu/SchemeImplementations/ ...))
   (make-graph-element
    'http://sicp.csail.mit.edu/getting-help.html
    '(http://sicp.csail.mit.edu/
      http://sicp.csail.mit.edu/SchemeImplementations/)
    '(... words extracted from http://sicp.csail.mit.edu/getting-help.html))
   ...))
#+END_SRC

Explain why our depth first strategy (using =DFS-simple=) will fail on this
graph. (If it helps, note that this graph has the same kind of form as Figure
1.) What is the essential difference between the =test-graph= and =the-web=
examples that cause =DFS-simple= to fail here?

We reason though following steps:
1. We can explain this situation by simulating with substitution model on each
   case and capture the common pattern appears all of each; we are allowed to
   use substitution model since =DFS-simple= doesn't involve any mutation in it.
2. The captured one is if given graph has cycle(s) in it, then =DFS-simple=
   fails, i.e. it falls into infinite loop over that cycle, which is the one the
   traverser encountered first.


You should make sure that you understand what I've described above using the
substitution model with some example.
** Programming assignment: A web spider
Begin by loading the code for the project from the web site. This will define
the search and data structure procedures listed above. Just to make sure
everything is working, evaluate

#+BEGIN_SRC scheme
(DFS-simple 'a
            (lambda (node) (eq? node 'l))
            test-graph)
#+END_SRC

This should traverse the =test-graph= graph until the search finds node =l=
(lowercase =L=), and you should see the nodes being visited in depth-first order
like this:
#+BEGIN_SRC scheme
(DFS-simple 'a
            (lambda (node) (eq? node 'l))
            test-graph)
(now-at a)
(now-at b)
(now-at c)
(now-at d)
(now-at e)
(now-at f)
(now-at g)
(now-at h)
(now-at i)
(now-at j)
(now-at k)
(now-at l)
;Value: #t
#+END_SRC

*** Computer Exercise 1: A breadth-first search.
Our previous example used a depth-first strategy. A breadth-first search
strategy can be obtained by modifying /only one line/ of the =DFS-simple=,
leaving the total number of characters in the expression unchanged! Do this to
create a new procedure (call it =DFS-simple=), demonstrate that it works on
=test-graph=, and write a short (but clear) explanation of why it works.

The answer is
#+BEGIN_SRC scheme
(define (BFS-simple start goal? graph)
  (search start
          goal?
          find-node-children
          (lambda (new old) (append old new))
          graph))
#+END_SRC
since it visits new added nodes only after visiting old nodes; i.e. it will
basically take the list of nodes to be explored, and add the new children to the
end of the list. This should give =BFS= as it visits child nodes only after
visiting all the siblings.
*** Marking nodes
In Warmup Exercise 2, we discussed a problem with =DFS-simple=. One way to fix
this problem is to keep track of what nodes we have visited. The basic idea is
that when we move to a "new" node, we can check to see if we have already
examined that node. If we have, we can simply remove it from our list of nodes
to explore, ignore any children (since they will have also already been
visited), and move on to the next node in the list.
*** Computer Exercise 2: Marking visited nodes.
We should be able to use the definition of =search= as a starting point to
create a new procedure (call it =search-with-cycles=) that keeps track of
already visited nodes, and implements the idea described above.

To show that our implementation works, we should use it with a depth first
strategy to create a new procedure (call it =DFS=) that implements full depth
first search. Use it to walk the sample graph =test-cycle= which is defined for
us in =search.scm=. Show it visits nodes at most once. Also create a breadth
first search, and also show that it only visits nodes once (albeit in a
different order).

Once we get sure these procedures are working, give the order in which the nodes
are visited for depth-first search and for breadth first search of =the-web=. We
should provide a =goal?= procedure that always returns false so that the entire
web is traversed, and start the walk at the node labeled
=http://sicp.csail.mit.edu/=.

**** Implementation
We can implement requested procedures using either with assignment or in
functional programming style. Here we consider functional programming style, you
should come up with the imperative style easily as well.

In functional programming, we need additional parameter to keep track of the
state variable named =visited=, which stores all the nodes it visited:
#+BEGIN_SRC scheme
(define (search-with-cycles initial-state goal? successors merge graph)
  ;; initial-state is the start state of the search
  ;;
  ;; goal? is the predicate that determines whether we have
  ;; reached the goal
  ;;
  ;; successors computes from the current state all successor states
  ;;
  ;; merge combines new states with the set of states still to explore
  (define (search-inner still-to-do visited)
    ;; visited stores all the nodes traversed so far.
    (if (null? still-to-do)
        #f
        (let ((current (car still-to-do)))
          (if *search-debug*
              (write-line (list 'now-at current)))
          (cond ((memv current visited)
                 (search-inner (cdr still-to-do) visited))
                ((goal? current) #t)
                (else (search-inner     ;recursive case
                       (merge (successors graph current) (cdr still-to-do))
                       (cons current visited)))))))
  (search-inner (list initial-state) '()))
#+END_SRC

And the =DFS=:
#+BEGIN_SRC scheme
(define (DFS start goal? graph)
  (search-with-cycles start
                      goal?
                      find-node-children
                      (lambda (new old) (append new old))
                      graph))
#+END_SRC

And the test:
#+BEGIN_SRC scheme
test-cycle

;Value: (graph (graph-element a (b c) (words for node a)) (graph-element b (c) (words for node b)) (graph-element c (a) (words for node c)))

(DFS 'a
     (lambda (node) false)
     test-cycle)
(now-at a)
(now-at b)
(now-at c)
(now-at a)
(now-at c)
;Value: #f
#+END_SRC

The structure of =test-cycle= can be structured as following figure:
#+BEGIN_SRC dot :file ../image/fig3.png
digraph {
A -> { B C };
B -> C;
C -> A;
}
#+END_SRC

#+caption: Figure 3: The abstract structure of test-cycle.
#+RESULTS:
[[file:../image/fig3.png]]

Our procedure works as expected? Yes and no!
- We expected to terminate even with the graph that contains cycle; and it is.
- We also expected to visit each node at most once; but not!


What's wrong with our =DFS= or =search-with-cycles=? The answer is nothing! just
we misused the debug code in the wrong place the canonical place would be the
after the checking whether the current is visited already or not:
#+BEGIN_SRC scheme
(define (search-with-cycles initial-state goal? successors merge graph)
  ;; initial-state is the start state of the search
  ;;
  ;; goal? is the predicate that determines whether we have
  ;; reached the goal
  ;;
  ;; successors computes from the current state all successor states
  ;;
  ;; merge combines new states with the set of states still to explore
  (define (search-inner still-to-do visited)
    ;; visited stores all the nodes traversed so far.
    (if (null? still-to-do)
        #f
        (let ((current (car still-to-do)))
          (cond ((memv current visited) ;if it visied then skip this node (as well as its children)
                 (search-inner (cdr still-to-do) visited))
                (else                   ;else visit!
                 (if *search-debug*
                     (write-line (list 'now-at current)))
                 (if (goal? current) #t
                     (search-inner      ;recursive case
                      (merge (successors graph current) (cdr still-to-do))
                      (cons current visited))))))))
  (search-inner (list initial-state) '()))
#+END_SRC

Then our test works as
#+BEGIN_SRC scheme
(DFS 'a
     (lambda (node) false)
     test-cycle)
(now-at a)
(now-at b)
(now-at c)
;Value: #f
#+END_SRC
as expected.

Then =BFS= is analogous to =DFS=:
#+BEGIN_SRC scheme
(define (BFS start goal? graph)
  (search-with-cycles start
                      goal?
                      find-node-children
                      (lambda (new old) (append old new))
                      graph))
#+END_SRC

As usual we test =BFS=:
#+BEGIN_SRC scheme
(BFS 'a
     (lambda (node) false)
     test-cycle)
(now-at a)
(now-at b)
(now-at c)
;Value: #f
#+END_SRC

=BFS= visits nodes same order as =DFS= coincidently.
**** Application to =the-web=
To make available =the-web= we should first load appropriate Scheme source file
that contains which:
#+BEGIN_SRC scheme
(load "generate.scm")

;Loading "generate.scm"... done
;Value: generate-random-web

the-web

;Value: (graph (graph-element http://sicp.csail.mit.edu/...
#+END_SRC

Then let's do the right things!
#+BEGIN_SRC scheme
(DFS 'http://sicp.csail.mit.edu/
     (lambda (node) false)
     the-web)
(now-at http://sicp.csail.mit.edu/)
(now-at http://sicp.csail.mit.edu/schemeimplementations)
(now-at http://sicp.csail.mit.edu/getting-help.html)
(now-at http://sicp.csail.mit.edu/lab-use.html)
(now-at *the-goal*)
(now-at http://sicp.csail.mit.edu/psets)
;Value: #f

(BFS 'http://sicp.csail.mit.edu/
     (lambda (node) false)
     the-web)
(now-at http://sicp.csail.mit.edu/)
(now-at http://sicp.csail.mit.edu/schemeimplementations)
(now-at http://sicp.csail.mit.edu/psets)
(now-at http://sicp.csail.mit.edu/getting-help.html)
(now-at http://sicp.csail.mit.edu/lab-use.html)
(now-at *the-goal*)
;Value: #f
#+END_SRC

Now the distinct two strategies produce different order of visiting.
** Indexing the web
Now let's turn to the problem of creating a full-text index of documents on the
Web, like the one created by Google or other search engines. We'll assume that
we have a graph that represents the World Wide Web, and this graph uses node
names that correspond to URLs (as in =the-web= sample given earlier). Remember,
we're assuming that we have a procedure =find-URL-text= which, for this web
representation, gets us the alphabetized text at the node. For example,
=(find-URL-text the-web 'http://sicp.csail.mit.edu/)= yields the list:
#+BEGIN_SRC scheme
(18:30:02 2004 6001-WEBMASTER@CSAIL.MIT.EDU 8 ABOUT ALL AM AND ANNOUNCEMENTS
          ANSWERS ARE ASSIGNMENT ASSIGNMENTS BY CALENDAR CAN CHANGE
          COLLABORATIVE COMMENTS COMPUTER COPYRIGHT CURRENT DO DOCUMENTATION EDT
          FALL FIND FOR GENERAL GET GETTING GUIDELINES HELP HOW I IN INDIVIDUAL
          INFORMATION INSTITUTE INTERPRETATION IS LAST LECTURE MASSACHUSETTS ME
          MICROQUIZZES MODIFIED MY NEW NOTES OCT OF ON ON-LINE ORAL OWN PAST
          POLICY POSTED PRESENTATIONS PREVIOUS PROBLEM PROGRAMS RECITATION
          RECITATIONS RECORDS RESERVED RIGHTS SCHEME SECTION SECTIONS SEND SET
          SETS SITE SOFTWARE STAFF STRUCTURE SUBJECT TECHNOLOGY TELL TERMS THE
          THIS THU TO UP USE WEEK WHAT WHERE WHICH WORK WRITING)
#+END_SRC

*** Computer Exercise 3: The Index Abstraction
Our first task is to complete the implementation of the =index= abstraction.
Complete the definition of =add-to-index!= so that have we available the
following procedures:
- =(make-index)= :: Creates a new index.
- =(add-to-index! index key value)= :: Add the value under the given key in the index.
- =(find-in-index index key)= :: Returns a list of all the values that have been
     entered into the index under the specified key.


Verify that our =add-to-index!= works with the other index procedures by showing
the result of evaluating the insertions and finds presented in Warmup Exercise 1.
* Footnotes

[fn:4] It is due to the existence of the cycle within the graph.

[fn:3] To implement such ADT, we need to use the message passing style which we
supposed to have not learned yet; also we supposed to not know exactly what is
/object/, which referenced in the discourse, that is core entity composing the
message passing programming.


[fn:2] Conceptually graph become a procedure that takes nodes with the edges,
which describe the connectivity between nodes, then connect the nodes according
to given edges; And it would return root node. Its purpose is side-effect --
connecting the nodes.


[fn:1] In fact, when I worked in software company, where develop program using
machine learning, I've implemented server side application that has the features
of cloud server; in there, I've dealt with HTTP (REST API) to do the task for
the purpose of training.
